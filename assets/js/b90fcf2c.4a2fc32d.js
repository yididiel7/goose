(self.webpackChunkgoose=self.webpackChunkgoose||[]).push([[9376],{46792:(e,n,t)=>{"use strict";t.d(n,{$:()=>a});t(96540);var i=t(74848);const a=e=>{let{children:n,className:t="",variant:a="default",size:r="default",...s}=e;return(0,i.jsx)("button",{className:`flex rounded-full focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-accent dark:focus:ring-offset-gray-900 ${{default:"bg-black dark:bg-white text-white dark:text-black hover:bg-accent/90 dark:hover:bg-accent/80",ghost:"bg-transparent hover:bg-gray-100 dark:hover:bg-gray-700 dark:text-gray-300",link:"bg-transparent text-accent hover:underline hover:text-textProminent dark:text-accent/90"}[a]} ${{default:"px-6 py-3",icon:"p-2"}[r]} ${t}`,...s,children:n})}},41337:(e,n,t)=>{"use strict";t.r(n),t.d(n,{default:()=>T});var i=t(58368),a=t(54472),r=t(56289),s=t(96540),o=t(58069),l=t(86297),c=t(51657),d=t(41547),m=t(74848);function u(e){return{id:e.command,name:e.name,command:e.command,url:e.url,description:e.name,is_builtin:e.is_builtin,link:e.link||"",installation_notes:e.installation_notes||"",endorsed:!1,environmentVariables:e.environmentVariables||[],githubStars:0}}function p(e){let{prompt:n}=e;const[t,p]=(0,s.useState)(null);return(0,m.jsx)(r.A,{to:`/prompt-library/detail?id=${n.id}`,className:"block no-underline hover:no-underline",children:(0,m.jsx)("div",{className:"extension-title h-full",children:(0,m.jsxs)("div",{className:"server-card interactive w-full h-full",children:[(0,m.jsx)("div",{className:"card-glow"}),(0,m.jsxs)("div",{className:"prompt-card",children:[(0,m.jsx)("div",{className:"card-header",children:(0,m.jsx)("div",{className:"card-header-content",children:(0,m.jsx)("span",{className:"home-page-server-name",children:n.title})})}),(0,m.jsx)("div",{className:"prompt-card-content",children:(0,m.jsxs)("div",{children:[(0,m.jsx)("div",{children:(0,m.jsx)("p",{className:"card-description",children:n.description})}),(0,m.jsx)("div",{className:"mt-6",children:(0,m.jsx)("div",{className:"border-t border-borderSubtle pt-4",children:(0,m.jsx)("div",{className:"flex flex-wrap gap-3",children:n.extensions.map(((e,n)=>(0,m.jsxs)("div",{className:"flex flex-col",children:[(0,m.jsxs)("div",{className:`\n                              inline-flex items-center h-9 px-4 rounded-full \n                              bg-background-subtle border border-borderSubtle\n                              transition-all duration-150 ease-in-out\n                              hover:bg-background-standard hover:border-borderStandard\n                              group ${e.is_builtin?"cursor-help":"cursor-pointer"}\n                              ${t===e.command?"bg-background-standard border-borderStandard":""}\n                            `,onClick:n=>{n.preventDefault(),n.stopPropagation(),e.is_builtin||p(t===e.command?null:e.command)},title:e.is_builtin?"Built-in extension - can be enabled in settings":"Click to see installation options",children:[(0,m.jsx)("span",{className:"text-sm text-textStandard group-hover:text-textProminent",children:e.name}),e.is_builtin?(0,m.jsx)("div",{className:"inline-flex items-center ml-2",children:(0,m.jsx)("span",{className:"text-sm text-textSubtle",children:"Built-in"})}):(0,m.jsx)("span",{className:"ml-2 text-textSubtle",children:(0,m.jsx)(i.A,{className:"h-4 w-4"})})]}),(0,m.jsx)(l.N,{children:!e.is_builtin&&t===e.command&&(0,m.jsx)(c.P.div,{initial:{height:0,opacity:0},animate:{height:"auto",opacity:1},exit:{height:0,opacity:0},transition:{duration:.2},className:"overflow-hidden",children:(0,m.jsxs)("div",{className:"mt-2 bg-background-subtle rounded-md p-3 border border-borderSubtle space-y-3",children:[(0,m.jsxs)("a",{href:(0,d.H)(u(e)),target:"_blank",rel:"noopener noreferrer",className:"flex items-center gap-2 text-textStandard hover:text-textProminent",onClick:e=>e.stopPropagation(),children:[(0,m.jsx)(i.A,{className:"h-4 w-4"}),(0,m.jsx)("span",{className:"text-sm",children:"Install via Desktop"})]}),(0,m.jsx)("div",{className:"border-t border-borderSubtle"}),(0,m.jsxs)("button",{className:"command-toggle",children:[(0,m.jsx)(a.A,{className:"h-4 w-4"}),(0,m.jsx)("h4",{className:"mx-2",children:"Command"})]}),e.url?(0,m.jsxs)(o.A,{language:"bash",children:['goose session --with-remote-extension "',e.url,'"']}):(0,m.jsxs)(o.A,{language:"bash",children:['goose session --with-extension "',e.command,'"']})]})})})]},n)))})})})]})})]})]})})})}var g=t(43938),h=t(52362),v=t(18907),f=t(46792),y=t(34164),b=t(50856);function x(){for(var e=arguments.length,n=new Array(e),t=0;t<e;t++)n[t]=arguments[t];return(0,b.QP)((0,y.$)(n))}function S(e){let{options:n,selectedValue:t,onChange:i}=e;return(0,m.jsx)("div",{className:"flex flex-wrap gap-2",children:n.map((e=>(0,m.jsx)("button",{onClick:()=>i(e.value),className:x("px-4 py-2 rounded-full text-sm font-medium transition-colors","border border-borderSubtle",t===e.value?"dark:bg-white dark:text-black bg-black text-white border-borderProminent":"bg-bgApp text-textStandard"),children:e.label},e.value)))})}function _(e){let{groups:n,selectedValues:t,onChange:i}=e;return(0,m.jsx)("div",{className:"w-64 pr-8",children:n.map((e=>(0,m.jsxs)("div",{className:"mb-8",children:[(0,m.jsx)("h3",{className:"text-lg font-medium mb-4 text-textProminent",children:e.title}),(0,m.jsx)("div",{className:"space-y-2",children:e.options.map((n=>(0,m.jsxs)("label",{className:"flex items-center justify-between group cursor-pointer",children:[(0,m.jsxs)("div",{className:"flex items-center",children:[(0,m.jsx)("input",{type:"checkbox",checked:(t[e.title]||[]).includes(n.value),onChange:()=>((e,n)=>{const a=t[e]||[],r=a.includes(n)?a.filter((e=>e!==n)):[...a,n];i(e,r)})(e.title,n.value),className:"form-checkbox h-4 w-4 text-purple-600 transition duration-150 ease-in-out"}),(0,m.jsx)("span",{className:"ml-2 text-sm text-textStandard group-hover:text-textProminent",children:n.label})]}),void 0!==n.count&&(0,m.jsx)("span",{className:"text-sm text-textSubtle",children:n.count})]},n.value)))})]},e.title)))})}var E=t(69158),w=t(25191);const A=[{label:"All",value:"all"},{label:"Business",value:"business"},{label:"Technical",value:"technical"},{label:"Productivity",value:"productivity"}],C=[{title:"Job",options:[{label:"Engineering",value:"engineering"},{label:"Design",value:"design"},{label:"Project Management",value:"project-management"},{label:"Marketing/Content",value:"marketing-content"},{label:"Data Analytics",value:"data-analytics"},{label:"Operations",value:"operations"}]}];function T(){const[e,n]=(0,s.useState)([]),[t,i]=(0,s.useState)(""),[a,r]=(0,s.useState)(!0),[o,l]=(0,s.useState)(null),[d,u]=(0,s.useState)(1),[y,b]=(0,s.useState)("all"),[x,T]=(0,s.useState)({}),[k,R]=(0,s.useState)(!1),I=20;return(0,s.useEffect)((()=>{const e=setTimeout((async()=>{try{r(!0),l(null);const e=await(0,v.I)(t);let i=e;"all"!==y&&(i=e.filter((e=>e.category===y))),Object.entries(x).forEach((e=>{let[n,t]=e;t.length>0&&(i=i.filter((e=>"Job"!==n||t.includes(e.job))))})),n(i)}catch(e){const n=e instanceof Error?e.message:"Unknown error";l(`Failed to load prompts: ${n}`),console.error("Error loading prompts:",e)}finally{r(!1)}}),300);return()=>clearTimeout(e)}),[t,y,x]),(0,s.useEffect)((()=>{const e=()=>{window.innerWidth>=768&&R(!1)};return window.addEventListener("resize",e),()=>window.removeEventListener("resize",e)}),[]),(0,m.jsx)(g.A,{children:(0,m.jsxs)("div",{className:"container mx-auto px-4 py-8 md:p-24",children:[(0,m.jsxs)("div",{className:"pb-8 md:pb-16",children:[(0,m.jsx)("h1",{className:"text-4xl md:text-[64px] font-medium text-textProminent",children:"Prompt Library"}),(0,m.jsx)("p",{className:"text-textProminent",children:"Your central directory for discovering and using effective prompts with Goose."})]}),(0,m.jsx)("div",{className:"search-container mb-6 md:mb-8",children:(0,m.jsx)("input",{className:"bg-bgApp font-light text-textProminent placeholder-textPlaceholder w-full px-3 py-2 md:py-3 text-2xl md:text-[40px] leading-tight md:leading-[52px] border-b border-borderSubtle focus:outline-none focus:ring-purple-500 focus:border-borderProminent caret-[#FF4F00] pl-0",placeholder:"Search for prompts by keywords",value:t,onChange:e=>{i(e.target.value),u(1)}})}),(0,m.jsx)("div",{className:"mb-6 md:mb-8 overflow-x-auto",children:(0,m.jsx)(S,{options:A,selectedValue:y,onChange:e=>{b(e),u(1)}})}),o&&(0,m.jsx)(h.A,{type:"danger",title:"Error",children:(0,m.jsx)("p",{children:o})}),(0,m.jsx)("div",{className:"md:hidden mb-4",children:(0,m.jsxs)(f.$,{onClick:()=>R(!k),className:"w-full flex items-center justify-center gap-2 py-2 px-4 bg-surfaceHighlight text-textProminent",children:[k?(0,m.jsx)(E.A,{size:20}):(0,m.jsx)(w.A,{size:20}),k?"Close Filters":"Show Filters"]})}),(0,m.jsxs)("div",{className:"flex flex-col md:flex-row gap-8",children:[(0,m.jsx)("div",{className:(k?"block":"hidden")+" md:block md:w-64 flex-shrink-0 transition-all duration-300 ease-in-out",children:(0,m.jsx)(_,{groups:C,selectedValues:x,onChange:(e,n)=>{T((t=>({...t,[e]:n}))),u(1)}})}),(0,m.jsxs)("div",{className:"flex-1",children:[(0,m.jsx)("div",{className:""+(t?"pb-2":"pb-4 md:pb-8"),children:(0,m.jsx)("p",{className:"text-gray-600",children:t?`${e.length} result${e.length>1?"s":""} for "${t}"`:""})}),a?(0,m.jsx)("div",{className:"py-8 text-xl text-gray-600",children:"Loading prompts..."}):0===e.length?(0,m.jsx)(h.A,{type:"info",children:(0,m.jsx)("p",{children:t?"No prompts found matching your search.":"No prompts available in the library yet."})}):(0,m.jsxs)(m.Fragment,{children:[(0,m.jsx)("div",{className:"grid grid-cols-1 lg:grid-cols-2 gap-4 md:gap-6",children:e.slice((d-1)*I,d*I).map((e=>(0,m.jsx)(c.P.div,{initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.6},children:(0,m.jsx)(p,{prompt:e},e.id)},e.id)))}),e.length>I&&(0,m.jsxs)("div",{className:"flex justify-center items-center gap-2 md:gap-4 mt-6 md:mt-8",children:[(0,m.jsx)(f.$,{onClick:()=>u((e=>Math.max(e-1,1))),disabled:1===d,className:"px-3 md:px-4 py-2 rounded-md border border-border bg-surfaceHighlight hover:bg-surface text-textProminent disabled:opacity-50 disabled:cursor-not-allowed transition-colors text-sm md:text-base",children:"Previous"}),(0,m.jsxs)("span",{className:"text-textProminent text-sm md:text-base",children:["Page ",d," of ",Math.ceil(e.length/I)]}),(0,m.jsx)(f.$,{onClick:()=>u((n=>Math.min(Math.ceil(e.length/I),n+1))),disabled:d>=Math.ceil(e.length/I),className:"px-3 md:px-4 py-2 rounded-md border border-border bg-surfaceHighlight hover:bg-surface text-textProminent disabled:opacity-50 disabled:cursor-not-allowed transition-colors text-sm md:text-base",children:"Next"})]})]})]})]})]})})}},41547:(e,n,t)=>{"use strict";function i(e){if(e.is_builtin){return`goose://extension?${["cmd=goosed","arg=mcp",`arg=${encodeURIComponent(e.id)}`,`description=${encodeURIComponent(e.id)}`].join("&")}`}if(e.url){return`goose://extension?${[`url=${encodeURIComponent(e.url)}`,`id=${encodeURIComponent(e.id)}`,`name=${encodeURIComponent(e.name)}`,`description=${encodeURIComponent(e.description)}`,...e.environmentVariables.filter((e=>e.required)).map((e=>`env=${encodeURIComponent(`${e.name}=${e.description}`)}`))].join("&")}`}const n=e.command.split(" "),t=n[0],i=n.slice(1);return`goose://extension?${[`cmd=${encodeURIComponent(t)}`,...i.map((e=>`arg=${encodeURIComponent(e)}`)),`id=${encodeURIComponent(e.id)}`,`name=${encodeURIComponent(e.name)}`,`description=${encodeURIComponent(e.description)}`,...e.environmentVariables.filter((e=>e.required)).map((e=>`env=${encodeURIComponent(`${e.name}=${e.description}`)}`))].join("&")}`}t.d(n,{H:()=>i})},18907:(e,n,t)=>{"use strict";t.d(n,{F:()=>s,I:()=>r});const i=t(98403),a=i.keys().map((e=>{const n=i(e);return n.default||n}));async function r(e){const n=e.toLowerCase().split(" ").filter(Boolean);return n.length?a.filter((e=>{const t=[e.title,e.description,e.example_prompt,...e.extensions.map((e=>e.name))].join(" ").toLowerCase();return n.every((e=>t.includes(e)))})):a}async function s(e){return a.find((n=>n.id===e))||null}},98403:(e,n,t)=>{var i={"./accessibility-audit.json":79644,"./ai-content-detection.json":80518,"./api-endpoints-analysis.json":53478,"./asana-task-management.json":96586,"./content-calendar-generator.json":8820,"./data-model-design.json":93971,"./delivery-tracking-automation.json":4064,"./figma-to-code.json":45466,"./form-review-automation.json":26021,"./generate-storybook-entry.json":59353,"./generate-toc.json":79318,"./github-branch-pr.json":42353,"./hands-free-coding.json":59234,"./image-resize.json":47562,"./incident-analysis.json":50029,"./java-kotlin-test-migration.json":16598,"./jetbrains-java-upgrade.json":60386,"./js-express-setup.json":65420,"./make-phone-call.json":89476,"./marketing-budget-review.json":33791,"./multi-project-security-audit.json":91122,"./name-column-split.json":41179,"./performance-review-prep.json":95361,"./pieces-stand-up-status-report.json":21400,"./product-region-availability.json":57844,"./query-optimization.json":43596,"./regulatory-comparison.json":48766,"./retail-market-monitor.json":86867,"./roll-plan-analyzer.json":19948,"./sales-performance-analysis.json":64926,"./security-patterns.json":58156,"./social-post-adaptation.json":5308,"./system-control-research.json":88623,"./youtube-to-blog.json":36658};function a(e){var n=r(e);return t(n)}function r(e){if(!t.o(i,e)){var n=new Error("Cannot find module '"+e+"'");throw n.code="MODULE_NOT_FOUND",n}return i[e]}a.keys=function(){return Object.keys(i)},a.resolve=r,e.exports=a,a.id=98403},79644:e=>{"use strict";e.exports=JSON.parse('{"id":"accessibility-audit","title":"Website Accessibility Audit","description":"Conduct a comprehensive accessibility audit of a website, including keyboard navigation, color contrast, and ARIA compliance","category":"technical","job":"design","example_prompt":"Can you check if my website is accessible? Please conduct a full accessibility audit, focusing on the following:\\n\\n1. Keyboard Navigation: Test all interactive elements (links, buttons, dropdowns, etc.) to ensure they are accessible without a mouse.\\n\\n2. Color Contrast Analysis: Verify that all text and UI elements meet WCAG contrast ratio standards.\\n\\n3. Screen Reader Compatibility: Test whether a screen reader can properly interpret content and navigation.\\n\\n4. ARIA & Semantic HTML Validation: Identify any missing or misused ARIA attributes and ensure proper semantic structure.\\n\\n5. Error Identification & Screenshots: Provide a comprehensive report with identified issues, along with screenshots if necessary.\\n\\n6. Fixes & Code Recommendations: Suggest HTML, CSS, or JavaScript changes to resolve any compliance issues.\\n\\nHere is the website to test: [URL]. I want to ensure that our documentation meets accessibility standards. Please generate a detailed report with steps to fix any issues found.","example_result":"I\'ve completed the accessibility audit of your website. Here are the findings:\\n\\n1. Keyboard Navigation:\\n- All interactive elements are keyboard accessible\\n- Focus indicators are visible\\n- Tab order is logical\\n\\n2. Color Contrast:\\n- Main text meets WCAG AA standards (ratio 4.5:1)\\n- Warning: Header text #FF8C00 on white background fails contrast requirements\\n\\n3. Screen Reader Compatibility:\\n- All images have appropriate alt text\\n- Headings are properly structured (H1 \u2192 H2 \u2192 H3)\\n- Form fields have associated labels\\n\\n4. ARIA & Semantic HTML:\\n- Navigation uses <nav> element correctly\\n- Missing aria-label on search form\\n- Article sections use appropriate semantic tags\\n\\nRecommended Fixes:\\n\\n```html\\n\x3c!-- Update header text color for better contrast --\x3e\\n<h1 style=\\"color: #D35400;\\">Welcome</h1>\\n\\n\x3c!-- Add aria-label to search form --\x3e\\n<form aria-label=\\"Search website\\">\\n  <input type=\\"search\\" name=\\"q\\">\\n</form>\\n```\\n\\nPriority fixes:\\n1. Adjust header text color to meet contrast requirements\\n2. Add missing ARIA labels to interactive elements\\n3. Implement skip navigation for keyboard users","extensions":[{"name":"Puppeteer","command":"npx -y @modelcontextprotocol/server-puppeteer","is_builtin":false,"environmentVariables":[]},{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[]}]}')},80518:e=>{"use strict";e.exports=JSON.parse('{"id":"ai-content-detection","title":"AI Content Detection Policies","description":"Enforce content policies by detecting AI-generated submissions and ensuring compliance with platform guidelines","category":"business","job":"marketing-content","example_prompt":"Please analyze the provided content for:\\n1. Indicators of AI generation\\n2. Policy compliance issues\\n3. Required disclosures or missing attributions\\n\\nProvide a detailed report including:\\n- AI detection confidence score\\n- Policy violation alerts\\n- Recommended actions\\n- Suggested improvements for compliance","example_result":"Content Analysis Report\\n\\nSubmitted Text: \\"The Future of Quantum Computing\\"\\n\\nAI Detection Results:\\n- Confidence Score: 87% likely AI-generated\\n- Key Indicators:\\n  - Consistent writing style throughout\\n  - Advanced technical terminology used uniformly\\n  - Repetitive phrase patterns detected\\n  - Limited personal perspective or anecdotes\\n\\nPolicy Compliance Review:\\n1. Attribution Issues:\\n  - Missing citations for technical claims\\n  - No references to original research\\n  - Required attribution disclaimer absent\\n\\n2. Content Guidelines:\\n  - Technical accuracy: Passed\\n  - Originality check: Failed (similar content found)\\n  - Disclosure requirements: Not met\\n\\nRequired Actions:\\n1. Add AI-generated content disclaimer\\n2. Include citations for technical claims\\n3. Differentiate from existing published content\\n4. Add human editorial oversight statement\\n\\nRecommended Improvements:\\n```markdown\\n# Original Content\\nThe Future of Quantum Computing...\\n\\n# Improved Version\\n[AI-Generated Content Disclaimer]\\nThe Future of Quantum Computing\\nEdited by: [Editor Name]\\n\\nAs explored in [Citation 1], quantum computing...\\n\\nAccording to research by [Institution]...\\n\\n# Footer\\nThis content was generated with AI assistance and reviewed by our editorial team. Citations and references available upon request.\\n```\\n\\nCompliance Score: 65/100\\nStatus: Requires Revision","extensions":[{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[]},{"name":"Google Drive","command":"npx -y @modelcontextprotocol/server-gdrive","is_builtin":false,"environmentVariables":[{"name":"GDRIVE_OAUTH_PATH","description":"/Users/<username>/.config/gcp-oauth.keys.json / ","required":true},{"name":"GDRIVE_CREDENTIALS_PATH","description":"/Users/<username>/.config/.gdrive-server-credentials.json /","required":true}]}]}')},53478:e=>{"use strict";e.exports=JSON.parse('{"id":"dev-api-endpoints-analysis","title":"Analyze App Endpoints and Interfaces","description":"Review application routing configuration and summarize all external interfaces","category":"technical","job":"engineering","example_prompt":"Please analyze the application\'s routing configuration found in `config/routes.rb` and summarize all external interfaces, including API endpoints, service integrations, and public routes.","example_result":"I\'ve analyzed the routing configuration in config/routes.rb. Here\'s a summary of all external interfaces:\\n\\n1. API Endpoints (v1):\\n```ruby\\n# Authentication\\nPOST   /api/v1/auth/login\\nPOST   /api/v1/auth/refresh\\nDELETE /api/v1/auth/logout\\n\\n# Users\\nGET    /api/v1/users\\nPOST   /api/v1/users\\nGET    /api/v1/users/:id\\nPATCH  /api/v1/users/:id\\nDELETE /api/v1/users/:id\\n\\n# Products\\nGET    /api/v1/products\\nPOST   /api/v1/products\\nGET    /api/v1/products/:id\\n```\\n\\n2. Public Routes:\\n- GET  / \u2192 Pages#home\\n- GET  /about \u2192 Pages#about\\n- GET  /contact \u2192 Pages#contact\\n- POST /contact \u2192 Messages#create\\n\\n3. Service Integrations:\\n- Stripe webhook: POST /webhooks/stripe\\n- SendGrid events: POST /webhooks/sendgrid\\n\\n4. OAuth Providers:\\n- GET /auth/google/callback\\n- GET /auth/github/callback\\n\\nSecurity Notes:\\n- All API endpoints require JWT authentication except /auth/login\\n- Rate limiting applied to authentication endpoints\\n- CORS configured for approved domains only\\n- API versioning implemented via URL prefix","extensions":[{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[]}]}')},96586:e=>{"use strict";e.exports=JSON.parse('{"id":"asana-task-management","title":"Manage Asana Tasks","description":"Create, update, and manage Asana tasks and projects","category":"productivity","job":"project-management","example_prompt":"Create a new task in my Asana workspace called \'Review Q4 metrics\' and set the due date to next Friday. Then, find all tasks assigned to me that are due this week and summarize them.","example_result":"I\'ve completed the following actions in Asana:\\n\\n1. Created new task:\\n- Title: \\"Review Q4 metrics\\"\\n- Due date: Friday, April 4th\\n- Status: Open\\n- Project: Business Review\\n\\n2. Tasks due this week assigned to you:\\n\\n- Monday: \\"Update sales dashboard\\" (Marketing)\\n- Tuesday: \\"Team sync meeting notes\\" (Team Management)\\n- Wednesday: \\"Client proposal review\\" (Sales)\\n- Thursday: \\"Monthly budget reconciliation\\" (Finance)\\n- Friday: \\"Review Q4 metrics\\" (Business Review)\\n\\nAll tasks have been properly tagged and linked to their respective projects. I\'ve also added the Q4 metrics task to your My Tasks list for easy access.","extensions":[{"name":"Asana","command":"npx -y @modelcontextprotocol/server-asana","is_builtin":false,"environmentVariables":[{"name":"ASANA_ACCESS_TOKEN","description":"Your Asana Personal Access Token.","installation_notes":"Use OpenAI\'s GPT-4o was used for this prompt","required":true}]},{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[]}]}')},8820:e=>{"use strict";e.exports=JSON.parse('{"id":"content-calendar-generator","title":"Content Calendar Generator","description":"Generate a content calendar with social media posts, blog topics, and email newsletters","category":"productivity","job":"marketing-content","featured":true,"example_prompt":"Help me create a content calendar for the next month. I need:\\n\\n1. Social media posts (3 per week)\\n2. Blog post topics (1 per week)\\n3. Email newsletter ideas (2 per month)\\n\\nOur target audience is developers and tech professionals. Focus on topics around AI, developer tools, and productivity. Include suggested posting times and content types (image, video, text).","example_result":"I\'ve created a content calendar for next month. Here\'s the breakdown:\\n\\nWeek 1:\\nSocial Media:\\n- Monday 9am: \\"\ud83d\udd25 Just launched: Our new AI-powered code completion tool. Watch the demo! [Video]\\"\\n- Wednesday 2pm: \\"Top 5 VS Code extensions for productivity in 2025 [Image carousel]\\"\\n- Friday 4pm: \\"What\'s your go-to debugging technique? Share below! [Poll]\\"\\n\\nBlog: \\"The Future of AI Pair Programming: Beyond Code Completion\\"\\n\\nWeek 2:\\nSocial Media:\\n- Monday 10am: \\"Developer tip: Use these keyboard shortcuts to boost your workflow [Infographic]\\"\\n- Wednesday 3pm: \\"Behind the scenes: How we optimized our CI/CD pipeline [Thread]\\"\\n- Friday 1pm: \\"Weekend project: Build a ChatGPT plugin in 30 minutes [Tutorial link]\\"\\n\\nBlog: \\"Optimizing Docker Builds: A Practical Guide\\"\\n\\nWeek 3:\\nSocial Media:\\n- Monday 9am: \\"Meet our engineering team and their favorite dev tools [Team photo]\\"\\n- Wednesday 2pm: \\"Quick tip: Debug faster with these console.log alternatives [Code snippet]\\"\\n- Friday 3pm: \\"From monolith to microservices: Our journey [Case study]\\"\\n\\nBlog: \\"Security Best Practices for AI Applications\\"\\n\\nWeek 4:\\nSocial Media:\\n- Monday 11am: \\"New feature alert: AI-powered code review assistant [Demo video]\\"\\n- Wednesday 1pm: \\"The evolution of JavaScript: 2015 vs 2025 [Comparison image]\\"\\n- Friday 4pm: \\"What\'s your biggest coding pet peeve? [Interactive poll]\\"\\n\\nBlog: \\"Building Scalable Systems with Kubernetes and AI\\"\\n\\nEmail Newsletters:\\n1. Mid-month (15th):\\nSubject: \\"Level Up Your Dev Game: AI Tools Special\\"\\n- Feature story: The impact of AI on code review\\n- Product updates\\n- Community spotlight\\n- Upcoming webinar announcement\\n\\n2. Month-end (30th):\\nSubject: \\"Monthly Dev Digest: Top Stories & Updates\\"\\n- Blog roundup\\n- Most engaging social posts\\n- Industry news\\n- Developer resource of the month\\n\\nAll content has been added to your Google Calendar with reminders set 2 days before each posting date.","extensions":[{"name":"Google Drive","command":"npx -y @modelcontextprotocol/server-gdrive","is_builtin":false,"link":"https://block.github.io/goose/v1/extensions/google-drive","environmentVariables":[{"name":"GDRIVE_OAUTH_PATH","description":"/Users/<username>/.config/gcp-oauth.keys.json","required":true},{"name":"GDRIVE_CREDENTIALS_PATH","description":"/Users/<username>/.config/.gdrive-server-credentials.json","required":true}]},{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[]}]}')},93971:e=>{"use strict";e.exports=JSON.parse('{"id":"developer-data-model-design","title":"Design and Validate Data Model","description":"Transform requirements into a concrete data model implementation with validation","category":"technical","job":"data-analytics","example_prompt":"I need help designing and prototyping a data model:\\n1. Here\'s my verbal description of the data model requirements: We\'re building a task management system for a software development team. We need to track:\\n- Projects with multiple tasks\\n- Task assignments to team members\\n- Task dependencies\\n- Time estimates and actual time spent\\n- Task status changes and history\\n- Comments and attachments on tasks\\n- Sprint/milestone assignments\\n\\n2. Can you help me transform this into a concrete implementation?\\n\\n3. Let\'s validate this against the following use cases:\\n- Team lead creates a new project and adds initial tasks\\n- Developer updates task status and logs time\\n- QA adds a blocking issue that depends on another task\\n- Manager generates sprint velocity report\\n- Team member adds comments and attachments to tasks\\n- System needs to track task history for auditing\\n- Tasks need to be easily searchable by various criteria\\n\\n4. We\'ll need to be able to iterate on this design based on our findings","example_result":"I\'ve designed a data model based on your requirements. Here\'s the implementation:\\n\\n```sql\\n-- Core tables\\nCREATE TABLE projects (\\n    id SERIAL PRIMARY KEY,\\n    name VARCHAR(100) NOT NULL,\\n    description TEXT,\\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\\n);\\n\\nCREATE TABLE users (\\n    id SERIAL PRIMARY KEY,\\n    email VARCHAR(255) UNIQUE NOT NULL,\\n    name VARCHAR(100) NOT NULL,\\n    role VARCHAR(50) NOT NULL\\n);\\n\\nCREATE TABLE tasks (\\n    id SERIAL PRIMARY KEY,\\n    project_id INTEGER REFERENCES projects(id),\\n    title VARCHAR(200) NOT NULL,\\n    description TEXT,\\n    status VARCHAR(50) NOT NULL,\\n    priority VARCHAR(20),\\n    estimated_hours DECIMAL(6,2),\\n    actual_hours DECIMAL(6,2),\\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\\n);\\n\\n-- Relationships and metadata\\nCREATE TABLE task_assignments (\\n    id SERIAL PRIMARY KEY,\\n    task_id INTEGER REFERENCES tasks(id),\\n    user_id INTEGER REFERENCES users(id),\\n    assigned_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\\n);\\n\\nCREATE TABLE task_dependencies (\\n    id SERIAL PRIMARY KEY,\\n    dependent_task_id INTEGER REFERENCES tasks(id),\\n    prerequisite_task_id INTEGER REFERENCES tasks(id),\\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\\n);\\n\\nCREATE TABLE sprints (\\n    id SERIAL PRIMARY KEY,\\n    name VARCHAR(100) NOT NULL,\\n    start_date DATE NOT NULL,\\n    end_date DATE NOT NULL,\\n    project_id INTEGER REFERENCES projects(id)\\n);\\n\\nCREATE TABLE sprint_tasks (\\n    sprint_id INTEGER REFERENCES sprints(id),\\n    task_id INTEGER REFERENCES tasks(id),\\n    PRIMARY KEY (sprint_id, task_id)\\n);\\n\\n-- Activity tracking\\nCREATE TABLE task_history (\\n    id SERIAL PRIMARY KEY,\\n    task_id INTEGER REFERENCES tasks(id),\\n    user_id INTEGER REFERENCES users(id),\\n    field_name VARCHAR(50) NOT NULL,\\n    old_value TEXT,\\n    new_value TEXT,\\n    changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\\n);\\n\\nCREATE TABLE time_logs (\\n    id SERIAL PRIMARY KEY,\\n    task_id INTEGER REFERENCES tasks(id),\\n    user_id INTEGER REFERENCES users(id),\\n    hours_spent DECIMAL(6,2) NOT NULL,\\n    description TEXT,\\n    logged_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\\n);\\n\\nCREATE TABLE comments (\\n    id SERIAL PRIMARY KEY,\\n    task_id INTEGER REFERENCES tasks(id),\\n    user_id INTEGER REFERENCES users(id),\\n    content TEXT NOT NULL,\\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\\n);\\n\\nCREATE TABLE attachments (\\n    id SERIAL PRIMARY KEY,\\n    task_id INTEGER REFERENCES tasks(id),\\n    user_id INTEGER REFERENCES users(id),\\n    file_name VARCHAR(255) NOT NULL,\\n    file_path VARCHAR(512) NOT NULL,\\n    file_size INTEGER NOT NULL,\\n    mime_type VARCHAR(100) NOT NULL,\\n    uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\\n);\\n```\\n\\nValidation against use cases:\\n\\n1. Team Lead Creates Project:\\n```sql\\n-- Create project\\nINSERT INTO projects (name, description) VALUES (\'Mobile App v2\', \'Version 2 of mobile app\');\\n\\n-- Add initial tasks\\nINSERT INTO tasks (project_id, title, status) \\nVALUES (1, \'Setup CI/CD pipeline\', \'TODO\');\\n```\\n\\n2. Developer Updates Task:\\n```sql\\n-- Update task status\\nUPDATE tasks SET status = \'IN_PROGRESS\' WHERE id = 1;\\n\\n-- Log time\\nINSERT INTO time_logs (task_id, user_id, hours_spent, description)\\nVALUES (1, 1, 2.5, \'Initial pipeline setup\');\\n```\\n\\n3. QA Adds Blocking Issue:\\n```sql\\n-- Create blocking issue\\nINSERT INTO tasks (project_id, title, status)\\nVALUES (1, \'Fix authentication bug\', \'BLOCKED\');\\n\\n-- Add dependency\\nINSERT INTO task_dependencies (dependent_task_id, prerequisite_task_id)\\nVALUES (2, 1);\\n```\\n\\n4. Sprint Velocity Query:\\n```sql\\nSELECT \\n    s.name as sprint_name,\\n    COUNT(t.id) as total_tasks,\\n    SUM(t.actual_hours) as total_hours,\\n    AVG(t.actual_hours) as avg_hours_per_task\\nFROM sprints s\\nJOIN sprint_tasks st ON s.id = st.sprint_id\\nJOIN tasks t ON st.task_id = t.id\\nWHERE s.project_id = 1\\nGROUP BY s.id, s.name;\\n```\\n\\n5. Comments and Attachments:\\n```sql\\n-- Add comment\\nINSERT INTO comments (task_id, user_id, content)\\nVALUES (1, 2, \'Pipeline config updated in PR #123\');\\n\\n-- Add attachment\\nINSERT INTO attachments (task_id, user_id, file_name, file_path)\\nVALUES (1, 2, \'pipeline-config.yml\', \'/uploads/123/pipeline-config.yml\');\\n```\\n\\n6. Task History Tracking:\\n```sql\\n-- Automatically tracked via trigger\\nCREATE TRIGGER track_task_changes\\nAFTER UPDATE ON tasks\\nFOR EACH ROW\\nEXECUTE FUNCTION log_task_change();\\n```\\n\\n7. Task Search Indexes:\\n```sql\\n-- Create indexes for common search patterns\\nCREATE INDEX idx_task_status ON tasks(status);\\nCREATE INDEX idx_task_project ON tasks(project_id);\\nCREATE INDEX idx_task_assignee ON task_assignments(user_id);\\nCREATE INDEX idx_task_sprint ON sprint_tasks(sprint_id);\\n```\\n\\nThis model supports all required functionality while maintaining data integrity and performance. The design is normalized to prevent data anomalies while including appropriate indexes for efficient querying.","extensions":[{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[]},{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[]}]}')},4064:e=>{"use strict";e.exports=JSON.parse('{"id":"ops-delivery-tracking","title":"Real-Time Delivery Route Optimization","description":"Monitor delivery routes and automatically optimize them based on real-time traffic conditions","category":"business","job":"operations","example_prompt":"Track the live GPS location of driver ID #{driver_id}. Query Google Maps for real-time traffic data and adjust the estimated delivery time if delays exceed 5 minutes. If ETA changes, update the customer\'s live tracker and send an SMS notification. If the delay is greater than 20 minutes, check if another driver within a 1-mile radius can take over the delivery.","example_result":"I\'ve analyzed the delivery route for driver #1234. Here\'s the current status:\\n\\nCurrent Location:\\n- Latitude: 37.7858\\n- Longitude: -122.4064\\n- Last Updated: 2 minutes ago\\n\\nRoute Analysis:\\n- Original ETA: 2:45 PM\\n- Current Traffic Conditions: Heavy congestion on Market St\\n- Delay Detected: 12 minutes\\n- New ETA: 2:57 PM\\n\\nActions Taken:\\n1. Updated customer tracking portal\\n2. Sent SMS to customer:\\n   \\"Your delivery is slightly delayed due to traffic. New ETA: 2:57 PM\\"\\n\\nNearby Drivers:\\n- Driver #1567: 0.8 miles away, 2 active deliveries\\n- Driver #1892: 1.2 miles away, 1 active delivery\\n\\nRecommendation:\\n- Delay is under 20 minutes threshold\\n- Current driver should continue the delivery\\n- Will continue monitoring and update if conditions change\\n\\nOptimized Route:\\n```json\\n{\\n  \\"original_route\\": [\\n    \\"Market St\\",\\n    \\"Van Ness Ave\\",\\n    \\"Hayes St\\"\\n  ],\\n  \\"new_route\\": [\\n    \\"Market St\\",\\n    \\"Gough St\\",\\n    \\"Hayes St\\"\\n  ],\\n  \\"estimated_time_saved\\": \\"8 minutes\\"\\n}\\n```\\n\\nNext Steps:\\n1. Driver has been notified of route change\\n2. System will continue monitoring traffic conditions\\n3. Next update in 5 minutes or if conditions change significantly","extensions":[{"name":"Google Maps","command":"npx -y @modelcontextprotocol/server-google-maps","is_builtin":false,"environmentVariables":[{"name":"GOOGLE_MAPS_API_KEY","description":"<YOUR_TOKEN>","required":true}]},{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[]}]}')},45466:e=>{"use strict";e.exports=JSON.parse('{"id":"design-figma-to-code","title":"Convert Designs to Code","description":"Convert a Figma design into a web app","category":"technical","job":"design","featured":true,"example_prompt":"Convert my figma design with file ID 7r0mLHWx2rrjwn79mcNVNE into a webpage. Get specific detailed information and styling about each element and components within each frame. Make sure to implement any interactions or animations and use a placeholder div with a gray background for images.\\n\\nSome elements are centralized, some are duplicated, make sure to get them correct. And ensure correct alignment and spacing between elements.","example_result":"I\'ve analyzed your Figma design and converted it into code. Here\'s the implementation:\\n\\n```html\\n<!DOCTYPE html>\\n<html lang=\\"en\\">\\n<head>\\n    <meta charset=\\"UTF-8\\">\\n    <meta name=\\"viewport\\" content=\\"width=device-width, initial-scale=1.0\\">\\n    <title>Landing Page</title>\\n    <style>\\n        .hero-section {\\n            display: flex;\\n            justify-content: space-between;\\n            padding: 64px 120px;\\n            background: linear-gradient(135deg, #F6F9FC 0%, #E9EEF3 100%);\\n        }\\n\\n        .hero-content {\\n            max-width: 540px;\\n        }\\n\\n        .hero-title {\\n            font-family: \'Inter\';\\n            font-weight: 700;\\n            font-size: 48px;\\n            line-height: 58px;\\n            color: #1A1A1A;\\n            margin-bottom: 24px;\\n        }\\n\\n        .feature-grid {\\n            display: grid;\\n            grid-template-columns: repeat(3, 1fr);\\n            gap: 32px;\\n            padding: 80px 120px;\\n        }\\n\\n        .feature-card {\\n            background: #FFFFFF;\\n            border-radius: 16px;\\n            padding: 32px;\\n            box-shadow: 0px 4px 12px rgba(0, 0, 0, 0.05);\\n            transition: transform 0.3s ease;\\n        }\\n\\n        .feature-card:hover {\\n            transform: translateY(-8px);\\n        }\\n    </style>\\n</head>\\n<body>\\n    <nav class=\\"navbar\\">\\n        \x3c!-- Navigation implementation --\x3e\\n    </nav>\\n\\n    <section class=\\"hero-section\\">\\n        <div class=\\"hero-content\\">\\n            <h1 class=\\"hero-title\\">Transform your workflow</h1>\\n            <p class=\\"hero-description\\">Streamline your process with our intuitive platform</p>\\n            <button class=\\"cta-button\\">Get Started</button>\\n        </div>\\n        <div class=\\"hero-image\\">\\n            \x3c!-- Placeholder for hero image --\x3e\\n            <div style=\\"width: 480px; height: 320px; background: #E5E5E5; border-radius: 8px;\\"></div>\\n        </div>\\n    </section>\\n\\n    <section class=\\"feature-grid\\">\\n        \x3c!-- Feature cards with hover animations --\x3e\\n        <div class=\\"feature-card\\">\\n            <div class=\\"icon\\">\x3c!-- Icon placeholder --\x3e</div>\\n            <h3>Feature 1</h3>\\n            <p>Description of feature 1</p>\\n        </div>\\n        \x3c!-- Repeated for other features --\x3e\\n    </section>\\n</body>\\n</html>\\n```\\n\\n```javascript\\n// Animation and interaction implementations\\ndocument.addEventListener(\'DOMContentLoaded\', () => {\\n    // Smooth scroll for navigation\\n    document.querySelectorAll(\'a[href^=\\"#\\"]\').forEach(anchor => {\\n        anchor.addEventListener(\'click\', function (e) {\\n            e.preventDefault();\\n            document.querySelector(this.getAttribute(\'href\')).scrollIntoView({\\n                behavior: \'smooth\'\\n            });\\n        });\\n    });\\n\\n    // Feature card hover effects\\n    const cards = document.querySelectorAll(\'.feature-card\');\\n    cards.forEach(card => {\\n        card.addEventListener(\'mouseenter\', () => {\\n            card.style.transform = \'translateY(-8px)\';\\n        });\\n        card.addEventListener(\'mouseleave\', () => {\\n            card.style.transform = \'translateY(0)\';\\n        });\\n    });\\n});\\n```\\n\\nImplementation Notes:\\n1. Responsive Design\\n   - Breakpoints set at 1200px, 992px, and 768px\\n   - Mobile-first approach using flexbox and grid\\n\\n2. Styling Details\\n   - Font: Inter (weights: 400, 500, 700)\\n   - Color palette from Figma variables\\n   - Shadow values matched exactly\\n\\n3. Animations\\n   - Smooth hover transitions (0.3s ease)\\n   - Scroll animations for sections\\n   - Interactive elements with feedback\\n\\n4. Component Structure\\n   - Modular CSS classes\\n   - Semantic HTML5 elements\\n   - Accessible markup with ARIA attributes\\n\\n5. Image Placeholders\\n   - Gray background (#E5E5E5)\\n   - Maintained aspect ratios\\n   - Ready for asset replacement","extensions":[{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[]},{"name":"Figma","command":"npx -y @hapins/figma-mcp","is_builtin":false,"environmentVariables":[{"name":"FIGMA_ACCESS_TOKEN","description":"Figma API access token","required":true}]}]}')},26021:e=>{"use strict";e.exports=JSON.parse('{"id":"operations-form-review-automation","title":"Assign Reviewers to Conference Proposals","description":"Automatically match incoming conference proposals with relevant track reviewers","category":"business","job":"operations","example_prompt":"I need help building an automated monitoring system that will:\\n1. Check an Airtable base every 10 minutes for new form submissions\\n2. Match each submission with reviewer information stored in a Google Sheet\\n3. Send me a notification with the submission details and assigned reviewer(s)\\n4. Auto-dismiss the notification after 5 seconds\\n\\nCan you help me create this system, starting with setting up the necessary connections to Airtable and Google Sheets?","example_result":"I\'ll help you create an automated monitoring system. Here\'s the implementation:\\n\\n1. First, let\'s create the monitoring script:\\n\\n```ruby\\nrequire \'airrecords\'\\nrequire \'google_drive\'\\nrequire \'terminal-notifier\'\\n\\n# Configure Airtable\\nAirrecords.api_key = ENV[\'AIRTABLE_API_KEY\']\\nclass Submission < Airrecords::Table\\n  self.base_key = \'your_base_id\'\\n  self.table_name = \'Submissions\'\\n\\n  def self.new_submissions\\n    all(filter: \\"{Status} = \'New\'\\")\\n  end\\nend\\n\\n# Configure Google Drive\\nsession = GoogleDrive::Session.from_config(\\"config.json\\")\\nreviewers_sheet = session.spreadsheet_by_key(\\"your_sheet_id\\").worksheets[0]\\n\\n# Load reviewer data\\ndef load_reviewers\\n  reviewers = {}\\n  reviewers_sheet.rows.each_with_index do |row, i|\\n    next if i == 0 # Skip header\\n    reviewers[row[1]] = {\\n      name: row[0],\\n      expertise: row[1].split(\',\'),\\n      current_load: row[2].to_i\\n    }\\n  end\\n  reviewers\\nend\\n\\n# Match submission with reviewers\\ndef match_reviewers(submission, reviewers)\\n  topic = submission[\'Topic\']\\n  matched_reviewers = reviewers.select do |_, r|\\n    r[:expertise].include?(topic) && r[:current_load] < 3\\n  end\\n  matched_reviewers.sort_by { |_, r| r[:current_load] }.first(2)\\nend\\n\\n# Main monitoring loop\\nloop do\\n  begin\\n    reviewers = load_reviewers\\n    new_submissions = Submission.new_submissions\\n\\n    new_submissions.each do |submission|\\n      matched = match_reviewers(submission, reviewers)\\n      \\n      if matched.any?\\n        # Update submission status\\n        submission[\'Status\'] = \'Assigned\'\\n        submission[\'Reviewers\'] = matched.map { |_, r| r[:name] }.join(\', \')\\n        submission.save\\n\\n        # Send notification\\n        message = \\"New submission: #{submission[\'Title\']}\\\\n\\"\\n        message += \\"Assigned to: #{submission[\'Reviewers\']}\\"\\n        \\n        TerminalNotifier.notify(\\n          message,\\n          title: \'New Conference Proposal\',\\n          execute: \'open https://airtable.com/your_base_url\',\\n          timeout: 5\\n        )\\n      end\\n    end\\n\\n  rescue => e\\n    TerminalNotifier.notify(\\n      \\"Error: #{e.message}\\",\\n      title: \'Monitoring System Error\'\\n    )\\n  end\\n\\n  sleep 600 # Wait 10 minutes\\nend\\n```\\n\\n2. Create a configuration file (config.json):\\n\\n```json\\n{\\n  \\"client_id\\": \\"your_google_client_id\\",\\n  \\"client_secret\\": \\"your_google_client_secret\\",\\n  \\"scope\\": [\\n    \\"https://www.googleapis.com/auth/drive\\",\\n    \\"https://spreadsheets.google.com/feeds/\\"\\n  ],\\n  \\"refresh_token\\": \\"your_refresh_token\\"\\n}\\n```\\n\\n3. Set up the launch agent (com.conference.monitor.plist):\\n\\n```xml\\n<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<!DOCTYPE plist PUBLIC \\"-//Apple//DTD PLIST 1.0//EN\\" \\"http://www.apple.com/DTDs/PropertyList-1.0.dtd\\">\\n<plist version=\\"1.0\\">\\n<dict>\\n    <key>Label</key>\\n    <string>com.conference.monitor</string>\\n    <key>ProgramArguments</key>\\n    <array>\\n        <string>/usr/bin/ruby</string>\\n        <string>/path/to/monitor.rb</string>\\n    </array>\\n    <key>RunAtLoad</key>\\n    <true/>\\n    <key>KeepAlive</key>\\n    <true/>\\n    <key>StandardErrorPath</key>\\n    <string>/tmp/conference.monitor.err</string>\\n    <key>StandardOutPath</key>\\n    <string>/tmp/conference.monitor.out</string>\\n    <key>EnvironmentVariables</key>\\n    <dict>\\n        <key>AIRTABLE_API_KEY</key>\\n        <string>your_airtable_api_key</string>\\n    </dict>\\n</dict>\\n</plist>\\n```\\n\\nImplementation Notes:\\n\\n1. Data Structure\\n   - Airtable: Submissions table with Title, Topic, Status, Reviewers fields\\n   - Google Sheet: Reviewers with Name, Expertise (comma-separated), Current Load\\n\\n2. Matching Logic\\n   - Matches based on topic expertise\\n   - Considers reviewer workload (max 3 assignments)\\n   - Assigns 2 reviewers per submission\\n\\n3. Error Handling\\n   - Catches and notifies on API errors\\n   - Continues running after errors\\n   - Logs to standard files\\n\\n4. Security\\n   - Credentials stored in environment/config\\n   - API keys not hardcoded\\n   - Limited scope for Google access\\n\\n5. Monitoring\\n   - Runs every 10 minutes\\n   - Auto-restarts if crashed\\n   - Clickable notifications to view details\\n\\nTo install:\\n1. Save the script as monitor.rb\\n2. Install required gems: `gem install airrecords google_drive terminal-notifier`\\n3. Copy plist to ~/Library/LaunchAgents/\\n4. Load with: `launchctl load ~/Library/LaunchAgents/com.conference.monitor.plist`","extensions":[{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[]},{"name":"Google Drive","command":"npx -y @modelcontextprotocol/server-gdrive","is_builtin":false,"environmentVariables":[{"name":"GDRIVE_OAUTH_PATH","description":"/Users/<username>/.config/gcp-oauth.keys.json / ","required":true},{"name":"GDRIVE_CREDENTIALS_PATH","description":"/Users/<username>/.config/.gdrive-server-credentials.json /","required":true}]}]}')},59353:e=>{"use strict";e.exports=JSON.parse("{\"id\":\"generate-storybook-entry\",\"title\":\"Generate Storybook Entry from Git Diff\",\"description\":\"Generate a Storybook documentation entry based on component changes in git diff\",\"category\":\"technical\",\"job\":\"engineering\",\"example_prompt\":\"Based on the current git diff, please generate a comprehensive Storybook entry for NavBar component that includes:\\n\\n1. Component description\\n2. Props documentation\\n3. Usage examples\\n4. Edge cases and variations\\n5. Accessibility considerations\\n\\nPlease format the output in MDX format suitable for Storybook.\",\"example_result\":\"Based on the git diff, I've generated a Storybook entry for the NavBar component:\\n\\n```mdx\\nimport { Meta, Story, Canvas, ArgsTable } from '@storybook/addon-docs';\\nimport { NavBar } from './NavBar';\\n\\n<Meta\\n  title=\\\"Components/Navigation/NavBar\\\"\\n  component={NavBar}\\n  argTypes={{\\n    variant: {\\n      control: 'select',\\n      options: ['primary', 'secondary', 'minimal'],\\n      description: 'Visual style variant of the navbar'\\n    },\\n    isSticky: {\\n      control: 'boolean',\\n      description: 'Whether navbar stays fixed at top during scroll'\\n    },\\n    logo: {\\n      control: 'text',\\n      description: 'URL or path to logo image'\\n    },\\n    menuItems: {\\n      control: 'object',\\n      description: 'Array of navigation items'\\n    }\\n  }}\\n/>\\n\\n# NavBar\\n\\nA responsive navigation bar component that adapts to different screen sizes and supports multiple visual styles.\\n\\n## Features\\n\\n- Responsive mobile menu with hamburger icon\\n- Configurable navigation items\\n- Optional sticky positioning\\n- Multiple visual variants\\n- Built-in search integration\\n- Accessible keyboard navigation\\n\\n## Props\\n\\n<ArgsTable of={NavBar} />\\n\\n## Basic Usage\\n\\n<Canvas>\\n  <Story name=\\\"Default\\\">\\n    <NavBar\\n      variant=\\\"primary\\\"\\n      logo=\\\"/logo.svg\\\"\\n      menuItems={[\\n        { label: 'Home', href: '/' },\\n        { label: 'Products', href: '/products' },\\n        { label: 'About', href: '/about' }\\n      ]}\\n    />\\n  </Story>\\n</Canvas>\\n\\n## Variants\\n\\n### Secondary Style\\n\\n<Canvas>\\n  <Story name=\\\"Secondary\\\">\\n    <NavBar\\n      variant=\\\"secondary\\\"\\n      logo=\\\"/logo.svg\\\"\\n      menuItems={[\\n        { label: 'Home', href: '/' },\\n        { label: 'Products', href: '/products' }\\n      ]}\\n    />\\n  </Story>\\n</Canvas>\\n\\n### Minimal Style\\n\\n<Canvas>\\n  <Story name=\\\"Minimal\\\">\\n    <NavBar\\n      variant=\\\"minimal\\\"\\n      menuItems={[\\n        { label: 'Home', href: '/' },\\n        { label: 'Products', href: '/products' }\\n      ]}\\n    />\\n  </Story>\\n</Canvas>\\n\\n## With Search\\n\\n<Canvas>\\n  <Story name=\\\"WithSearch\\\">\\n    <NavBar\\n      variant=\\\"primary\\\"\\n      showSearch={true}\\n      onSearch={(term) => console.log(`Searching for: ${term}`)}\\n      menuItems={[\\n        { label: 'Home', href: '/' },\\n        { label: 'Products', href: '/products' }\\n      ]}\\n    />\\n  </Story>\\n</Canvas>\\n\\n## Edge Cases\\n\\n### Long Menu Items\\n\\n<Canvas>\\n  <Story name=\\\"LongItems\\\">\\n    <NavBar\\n      menuItems={[\\n        { label: 'Home', href: '/' },\\n        { label: 'Very Long Product Category Name That Might Wrap', href: '/products' },\\n        { label: 'Another Really Long Navigation Item', href: '/about' }\\n      ]}\\n    />\\n  </Story>\\n</Canvas>\\n\\n### Many Items\\n\\n<Canvas>\\n  <Story name=\\\"ManyItems\\\">\\n    <NavBar\\n      menuItems={Array(8).fill().map((_, i) => ({\\n        label: `Item ${i + 1}`,\\n        href: `#${i}`\\n      }))}\\n    />\\n  </Story>\\n</Canvas>\\n\\n## Accessibility\\n\\nThe NavBar component implements the following accessibility features:\\n\\n- Uses semantic HTML5 nav element\\n- Implements ARIA landmarks for navigation\\n- Keyboard navigation support (Tab, Enter, Space, Esc)\\n- Mobile menu button follows ARIA menu button pattern\\n- Color contrast meets WCAG 2.1 AA standards\\n- Focus indicators visible in all themes\\n\\n### Keyboard Navigation\\n\\n- Tab: Move through navigation items\\n- Enter/Space: Activate current item\\n- Esc: Close mobile menu\\n- Arrow keys: Navigate dropdown menus\\n\\n## Implementation Notes\\n\\n```tsx\\n// Example TypeScript interfaces\\ninterface MenuItem {\\n  label: string;\\n  href: string;\\n  icon?: ReactNode;\\n  children?: MenuItem[];\\n}\\n\\ninterface NavBarProps {\\n  variant?: 'primary' | 'secondary' | 'minimal';\\n  isSticky?: boolean;\\n  logo?: string;\\n  menuItems: MenuItem[];\\n  showSearch?: boolean;\\n  onSearch?: (term: string) => void;\\n}\\n```\\n\\n## Best Practices\\n\\n1. Keep navigation items concise\\n2. Limit top-level items to 7 or fewer\\n3. Use consistent icons if implementing icon support\\n4. Ensure dropdown menus are keyboard accessible\\n5. Maintain mobile breakpoints in theme configuration\\n```\",\"extensions\":[{\"name\":\"Developer\",\"command\":\"developer\",\"is_builtin\":true,\"environmentVariables\":[{\"name\":\"component_name\",\"description\":\"Name of the component to document\",\"required\":true}]}]}")},79318:e=>{"use strict";e.exports=JSON.parse('{"id":"documentation-generate-toc","title":"Generate Table of Contents for Repo","description":"Generate a logically organized table of contents for a CONTRIBUTING.md file","category":"technical","job":"engineering","example_prompt":"Analyze the CONTRIBUTING.md file and create a well-structured table of contents. Include all major sections and subsections, using consistent formatting and logical organization.","example_result":"I\'ve analyzed the CONTRIBUTING.md file and generated a table of contents. Here\'s the structured output:\\n\\n```markdown\\n# Contributing to Project Name\\n\\n## Table of Contents\\n\\n1. [Getting Started](#getting-started)\\n   - [Prerequisites](#prerequisites)\\n   - [Development Environment](#development-environment)\\n   - [Code Style Guide](#code-style-guide)\\n\\n2. [Development Workflow](#development-workflow)\\n   - [Branching Strategy](#branching-strategy)\\n   - [Commit Messages](#commit-messages)\\n   - [Pull Requests](#pull-requests)\\n   - [Code Review Process](#code-review-process)\\n\\n3. [Testing Guidelines](#testing-guidelines)\\n   - [Unit Tests](#unit-tests)\\n   - [Integration Tests](#integration-tests)\\n   - [Performance Tests](#performance-tests)\\n   - [Test Coverage Requirements](#test-coverage-requirements)\\n\\n4. [Documentation](#documentation)\\n   - [Code Documentation](#code-documentation)\\n   - [API Documentation](#api-documentation)\\n   - [Example Usage](#example-usage)\\n   - [Architecture Diagrams](#architecture-diagrams)\\n\\n5. [Release Process](#release-process)\\n   - [Version Numbering](#version-numbering)\\n   - [Release Checklist](#release-checklist)\\n   - [Deployment Steps](#deployment-steps)\\n\\n6. [Community Guidelines](#community-guidelines)\\n   - [Code of Conduct](#code-of-conduct)\\n   - [Issue Reporting](#issue-reporting)\\n   - [Feature Requests](#feature-requests)\\n   - [Community Meetings](#community-meetings)\\n\\n7. [Support](#support)\\n   - [Getting Help](#getting-help)\\n   - [Troubleshooting](#troubleshooting)\\n   - [FAQ](#faq)\\n\\n8. [Legal](#legal)\\n   - [License](#license)\\n   - [Contributor License Agreement](#contributor-license-agreement)\\n   - [Third-party Dependencies](#third-party-dependencies)\\n```\\n\\nImplementation Notes:\\n\\n1. Structure\\n   - Organized in hierarchical order of engagement\\n   - Maximum 3 levels deep for clarity\\n   - Related topics grouped together\\n\\n2. Formatting\\n   - Consistent indentation for subsections\\n   - All sections properly linked\\n   - Clear numbering system\\n\\n3. Navigation\\n   - All links are lowercase, hyphenated\\n   - Sections ordered by logical flow\\n   - Progressive disclosure of information\\n\\n4. Coverage\\n   - Technical aspects (development, testing)\\n   - Process details (workflow, releases)\\n   - Community aspects (guidelines, support)\\n   - Legal requirements\\n\\n5. Maintainability\\n   - Each section is distinct\\n   - Easy to update and expand\\n   - Follows standard markdown practices","extensions":[{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[{"name":"file_path","description":"Path to the CONTRIBUTING.md file","required":true}]}]}')},42353:e=>{"use strict";e.exports=JSON.parse('{"id":"developer-github-branch-pr","title":"Create a GitHub Branch and a Pull Request","description":"Create a new branch, update README, and open a pull request on GitHub","category":"technical","job":"engineering","example_prompt":"Create a new branch called hello-world in my angiejones/goose-demo repository. Update the README.md file to say \\"this was written by goose\\" and commit it. Open a pull request with your changes.","example_result":"I\'ve created a new feature branch and pull request:\\n\\n1. Branch Creation:\\n```bash\\n$ git checkout -b feature/user-authentication\\n$ git add .\\n$ git commit -m \\"Add user authentication system\\n\\n- Implement JWT token handling\\n- Add password hashing\\n- Create login/logout endpoints\\"\\n$ git push origin feature/user-authentication\\n```\\n\\n2. Pull Request Details:\\n- Title: \\"Feature: User Authentication System\\"\\n- Base: main \u2190 feature/user-authentication\\n- Status: Open\\n\\nDescription:\\n```markdown\\n## Changes\\n- Implemented JWT-based authentication\\n- Added secure password hashing using bcrypt\\n- Created RESTful login/logout endpoints\\n- Added user session management\\n\\n## Testing\\n- Unit tests added for auth controllers\\n- Integration tests for login flow\\n- Security testing completed\\n\\n## Checklist\\n- [x] Tests passing\\n- [x] Security review completed\\n- [x] Documentation updated\\n```\\n\\nReviewers have been assigned and the CI pipeline is running.","extensions":[{"name":"GitHub","command":"npx -y @modelcontextprotocol/server-github","is_builtin":false,"environmentVariables":[{"name":"GITHUB_PERSONAL_ACCESS_TOKEN","description":"<YOUR_TOKEN>","required":true}]},{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[]}]}')},59234:e=>{"use strict";e.exports=JSON.parse('{"id":"hands-free-coding","title":"Hands-free Coding","description":"Use your voice to code","category":"technical","job":"engineering","example_prompt":"I\'d like to speak instead of typing","example_result":"I\'ll help you code using voice commands. I\'m now listening for your voice input.\\n\\nExample Voice Commands:\\n\\n\\"Create a new Python function called calculate total that takes a list of numbers and returns their sum\\"\\n\\n```python\\ndef calculate_total(numbers):\\n    return sum(numbers)\\n```\\n\\n\\"Add input validation to check if the list is empty\\"\\n\\n```python\\ndef calculate_total(numbers):\\n    if not numbers:\\n        raise ValueError(\\"List cannot be empty\\")\\n    return sum(numbers)\\n```\\n\\n\\"Add a docstring explaining the function\\"\\n\\n```python\\ndef calculate_total(numbers):\\n    \\"\\"\\"Calculate the sum of a list of numbers.\\n    \\n    Args:\\n        numbers (list): A list of numeric values\\n        \\n    Returns:\\n        float: The sum of all numbers in the list\\n        \\n    Raises:\\n        ValueError: If the input list is empty\\n    \\"\\"\\"\\n    if not numbers:\\n        raise ValueError(\\"List cannot be empty\\")\\n    return sum(numbers)\\n```\\n\\n\\"Add a test case for the function\\"\\n\\n```python\\ndef test_calculate_total():\\n    # Test normal case\\n    assert calculate_total([1, 2, 3]) == 6\\n    \\n    # Test floating points\\n    assert calculate_total([1.5, 2.5]) == 4.0\\n    \\n    # Test empty list\\n    try:\\n        calculate_total([])\\n        assert False, \\"Expected ValueError\\"\\n    except ValueError:\\n        pass\\n```\\n\\nVoice Command Tips:\\n1. Speak clearly and pause between commands\\n2. Use programming terms as you would write them\\n3. Say \\"undo\\" to revert last change\\n4. Say \\"run tests\\" to execute test cases\\n5. Common commands:\\n   - \\"Create function/class\\"\\n   - \\"Add parameter/argument\\"\\n   - \\"Import library\\"\\n   - \\"Add try-catch block\\"\\n   - \\"Create for loop\\"\\n   - \\"Add comment\\"\\n\\nI\'m still listening. What would you like to code next?","extensions":[{"name":"Speech","command":"uvx -p 3.10.14 speech-mcp@latest","is_builtin":false,"installation_notes":"[PortAudio](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/main/scripts/readme-gen/templates/install_portaudio.tmpl.rst#install-portaudio) is required for PyAudio to capture audio from your microphone","environmentVariables":[]},{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[]}]}')},47562:e=>{"use strict";e.exports=JSON.parse('{"id":"image-resize","title":"Resize Image with Aspect Ratio","description":"Resize an image while maintaining aspect ratio and quality.","category":"productivity","job":"design","example_prompt":"Resize my image {image_path} to be {width}x{height} pixels. Maintain the aspect ratio and image quality.","example_result":"I\'ll help you resize the image while maintaining its aspect ratio and quality. Here\'s what I\'ll do:\\n\\n1. Load and analyze the original image:\\n```python\\nfrom PIL import Image\\n\\n# Open the image\\nimg = Image.open(\'product_photo.jpg\')\\n\\n# Get original dimensions\\noriginal_width, original_height = img.size\\nprint(f\\"Original dimensions: {original_width}x{original_height}\\")\\n```\\n\\nOriginal dimensions: 2400x1600\\n\\n2. Calculate new dimensions preserving aspect ratio:\\n```python\\ntarget_width = 800\\ntarget_height = 600\\n\\n# Calculate scaling factor\\nwidth_ratio = target_width / original_width\\nheight_ratio = target_height / original_height\\nscale_factor = min(width_ratio, height_ratio)\\n\\n# Calculate new dimensions\\nnew_width = int(original_width * scale_factor)\\nnew_height = int(original_height * scale_factor)\\n\\nprint(f\\"New dimensions: {new_width}x{new_height}\\")\\n```\\n\\nNew dimensions: 800x533\\n\\n3. Perform the resize operation:\\n```python\\n# Resize using high-quality Lanczos resampling\\nresized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\\n\\n# Save with optimal quality settings\\nresized_img.save(\\n    \'product_photo_resized.jpg\',\\n    \'JPEG\',\\n    quality=95,\\n    optimize=True\\n)\\n```\\n\\nImage has been resized and saved as \'product_photo_resized.jpg\'\\n\\nResize Summary:\\n- Original size: 2400x1600 pixels\\n- Target size: 800x600 pixels\\n- Final size: 800x533 pixels\\n- Aspect ratio: Maintained (1.5:1)\\n- Resampling: Lanczos (high quality)\\n- Format: JPEG\\n- Quality: 95%\\n- Optimization: Enabled\\n\\nThe image has been resized to fit within the requested dimensions while maintaining its original proportions. I used Lanczos resampling for the highest quality output and saved with optimal JPEG compression settings to preserve image quality.\\n\\nWould you like me to show you a preview of the resized image?","extensions":[{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[]},{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[]}]}')},50029:e=>{"use strict";e.exports=JSON.parse('{"id":"data-incident-analysis","title":"Analyze PagerDuty Incident Patterns","description":"Analyze incident data to identify patterns and opportunities for reducing alert noise","category":"technical","job":"engineering","featured":true,"example_prompt":"Analyze the PagerDuty incident activity data to:\\n1. Identify most frequent issues and their patterns\\n2. Calculate incident frequencies and trends\\n3. Determine if issues are ongoing or resolved\\n4. Highlight top opportunities to reduce alert noise\\n5. Generate recommendations for alert optimization\\n\\nThe analysis should focus on actionable insights to reduce unnecessary pages and improve on-call experience.","example_result":"I\'ve analyzed the PagerDuty incident data. Here\'s the comprehensive analysis:\\n\\n# Incident Analysis Report\\n\\n## 1. High-Frequency Issues\\n\\n```sql\\nSELECT \\n    incident_type,\\n    COUNT(*) as occurrence_count,\\n    AVG(resolution_time_minutes) as avg_resolution_time\\nFROM incidents\\nGROUP BY incident_type\\nORDER BY occurrence_count DESC\\nLIMIT 5;\\n```\\n\\nTop 5 Most Frequent Issues:\\n1. CPU Usage Spike (127 incidents)\\n   - Peak times: 2-4 AM UTC\\n   - Avg resolution: 12 minutes\\n   - 92% auto-resolved\\n\\n2. Memory Warning (89 incidents)\\n   - Consistent pattern on app-server-03\\n   - Avg resolution: 8 minutes\\n   - 95% auto-resolved\\n\\n3. API Response Time (67 incidents)\\n   - Correlated with batch job schedule\\n   - Avg resolution: 45 minutes\\n   - 40% required manual intervention\\n\\n4. Disk Space Warning (52 incidents)\\n   - Recurring on logging servers\\n   - Avg resolution: 30 minutes\\n   - 70% resolved by log rotation\\n\\n5. Connection Timeout (43 incidents)\\n   - Database-related\\n   - Avg resolution: 28 minutes\\n   - 60% required manual intervention\\n\\n## 2. Temporal Analysis\\n\\n```python\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n# Incident frequency by hour\\ndf[\'hour\'] = pd.to_datetime(df[\'timestamp\']).dt.hour\\nhourlyCounts = df.groupby(\'hour\')[\'incident_id\'].count()\\n\\n# Plot distribution\\nplt.figure(figsize=(12, 6))\\nplt.bar(hourlyCounts.index, hourlyCounts.values)\\nplt.title(\'Incident Distribution by Hour\')\\nplt.xlabel(\'Hour (UTC)\')\\nplt.ylabel(\'Number of Incidents\')\\n```\\n\\nKey Patterns:\\n- 68% of alerts occur between 00:00-06:00 UTC\\n- Wednesday shows highest incident rate\\n- Month-end has 2.5x normal incident volume\\n\\n## 3. Issue Status Summary\\n\\nActive Issues:\\n- Memory leaks on app-server-03\\n  - Status: Under investigation\\n  - Impact: Medium\\n  - ETA: 48 hours\\n\\n- API response degradation\\n  - Status: Partially mitigated\\n  - Impact: Low\\n  - ETA: 24 hours\\n\\nResolved Issues:\\n- Database connection timeouts\\n  - Resolution: Connection pool optimization\\n  - Prevention: Added connection monitoring\\n\\n- Disk space warnings\\n  - Resolution: Automated log rotation\\n  - Prevention: Predictive cleanup jobs\\n\\n## 4. Alert Noise Reduction Opportunities\\n\\n1. High-Impact Opportunities:\\n   ```\\n   CPU Usage Alerts:\\n   - Current: 127 alerts/month\\n   - Potential: 15 alerts/month\\n   - Reduction: 88%\\n   - Effort: Low\\n   ```\\n\\n2. Medium-Impact Opportunities:\\n   ```\\n   Memory Warnings:\\n   - Current: 89 alerts/month\\n   - Potential: 20 alerts/month\\n   - Reduction: 78%\\n   - Effort: Medium\\n   ```\\n\\n## 5. Recommendations\\n\\n1. Immediate Actions:\\n```yaml\\n- Update CPU threshold:\\n    from: 80% for 1 minute\\n    to: 90% for 5 minutes\\n    impact: -85% alerts\\n\\n- Implement memory alert aggregation:\\n    window: 15 minutes\\n    condition: Same host\\n    impact: -70% alerts\\n```\\n\\n2. Short-term Improvements:\\n```yaml\\n- Add context to API alerts:\\n    - Include active connections\\n    - Add recent deploy info\\n    - Show batch job status\\n\\n- Enhance disk space monitoring:\\n    - Predict fill rate\\n    - Auto-trigger cleanup\\n    - Weekly trend analysis\\n```\\n\\n3. Long-term Projects:\\n```yaml\\n- Implement ML-based anomaly detection:\\n    priority: High\\n    effort: Large\\n    benefits:\\n      - 60% false positive reduction\\n      - Automated threshold adjustment\\n      - Pattern recognition\\n\\n- Develop unified alert dashboard:\\n    priority: Medium\\n    effort: Medium\\n    features:\\n      - Cross-service correlation\\n      - Historical pattern view\\n      - One-click suppression\\n```\\n\\n## Implementation Plan\\n\\n1. Week 1-2:\\n   - Adjust CPU thresholds\\n   - Configure alert aggregation\\n   - Update runbooks\\n\\n2. Week 3-4:\\n   - Deploy enhanced monitoring\\n   - Test new alert rules\\n   - Train on-call team\\n\\n3. Month 2:\\n   - Begin ML implementation\\n   - Collect baseline metrics\\n   - Develop dashboard\\n\\nExpected Outcomes:\\n- 75% reduction in non-actionable alerts\\n- 40% decrease in MTTR\\n- 60% improvement in on-call satisfaction\\n\\nWould you like me to generate detailed configuration changes for any specific recommendation?","extensions":[{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[]},{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[]}]}')},16598:e=>{"use strict";e.exports=JSON.parse('{"id":"java-kotlin-test-migration","title":"Migrate Java Tests to Kotlin","description":"Select Java tests and migrate them to Kotlin, including compilation verification","category":"technical","job":"engineering","example_prompt":"Please help migrate Java tests to Kotlin by:\\n1. Finding and selecting 5 Java test files\\n2. Converting each test to Kotlin while maintaining functionality\\n3. Removing original Java files\\n4. Verifying compilation with gradle\\n5. Generating migration diffs\\n\\nFor each test file:\\n- Create equivalent Kotlin test\\n- Maintain test structure and assertions\\n- Verify compilation success\\n- Generate diff for review","example_result":"I\'ll help you migrate the Java tests to Kotlin. Here\'s the migration process for one test file:\\n\\nOriginal Java Test:\\n```java\\n// UserServiceTest.java\\nimport org.junit.jupiter.api.Test;\\nimport static org.junit.jupiter.api.Assertions.*;\\nimport static org.mockito.Mockito.*;\\n\\npublic class UserServiceTest {\\n    private final UserRepository userRepository = mock(UserRepository.class);\\n    private final EmailService emailService = mock(EmailService.class);\\n    private final UserService userService = new UserService(userRepository, emailService);\\n\\n    @Test\\n    public void createUser_WithValidData_ShouldSucceed() {\\n        // Given\\n        UserDTO userDTO = new UserDTO(\\"john@example.com\\", \\"John Doe\\");\\n        User user = new User(userDTO.getEmail(), userDTO.getName());\\n        when(userRepository.findByEmail(userDTO.getEmail())).thenReturn(null);\\n        when(userRepository.save(any(User.class))).thenReturn(user);\\n\\n        // When\\n        User result = userService.createUser(userDTO);\\n\\n        // Then\\n        assertNotNull(result);\\n        assertEquals(userDTO.getEmail(), result.getEmail());\\n        assertEquals(userDTO.getName(), result.getName());\\n        verify(emailService).sendWelcomeEmail(user);\\n    }\\n\\n    @Test\\n    public void createUser_WithExistingEmail_ShouldThrowException() {\\n        // Given\\n        UserDTO userDTO = new UserDTO(\\"existing@example.com\\", \\"John Doe\\");\\n        when(userRepository.findByEmail(userDTO.getEmail()))\\n            .thenReturn(new User(userDTO.getEmail(), \\"Existing User\\"));\\n\\n        // When/Then\\n        assertThrows(UserAlreadyExistsException.class, () -> {\\n            userService.createUser(userDTO);\\n        });\\n        verify(userRepository, never()).save(any());\\n        verify(emailService, never()).sendWelcomeEmail(any());\\n    }\\n}\\n```\\n\\nMigrated Kotlin Test:\\n```kotlin\\n// UserServiceTest.kt\\nimport org.junit.jupiter.api.Test\\nimport org.junit.jupiter.api.assertThrows\\nimport org.mockito.kotlin.*\\nimport kotlin.test.assertEquals\\nimport kotlin.test.assertNotNull\\n\\nclass UserServiceTest {\\n    private val userRepository: UserRepository = mock()\\n    private val emailService: EmailService = mock()\\n    private val userService = UserService(userRepository, emailService)\\n\\n    @Test\\n    fun `create user with valid data should succeed`() {\\n        // Given\\n        val userDTO = UserDTO(email = \\"john@example.com\\", name = \\"John Doe\\")\\n        val user = User(email = userDTO.email, name = userDTO.name)\\n        whenever(userRepository.findByEmail(userDTO.email)).thenReturn(null)\\n        whenever(userRepository.save(any())).thenReturn(user)\\n\\n        // When\\n        val result = userService.createUser(userDTO)\\n\\n        // Then\\n        assertNotNull(result)\\n        assertEquals(userDTO.email, result.email)\\n        assertEquals(userDTO.name, result.name)\\n        verify(emailService).sendWelcomeEmail(user)\\n    }\\n\\n    @Test\\n    fun `create user with existing email should throw exception`() {\\n        // Given\\n        val userDTO = UserDTO(email = \\"existing@example.com\\", name = \\"John Doe\\")\\n        whenever(userRepository.findByEmail(userDTO.email))\\n            .thenReturn(User(email = userDTO.email, name = \\"Existing User\\"))\\n\\n        // When/Then\\n        assertThrows<UserAlreadyExistsException> {\\n            userService.createUser(userDTO)\\n        }\\n        verify(userRepository, never()).save(any())\\n        verify(emailService, never()).sendWelcomeEmail(any())\\n    }\\n}\\n```\\n\\nKey Changes Made:\\n1. File Extension: .java \u2192 .kt\\n2. Class Declaration: Removed \'public\'\\n3. Test Methods:\\n   - Removed \'public void\'\\n   - Added backtick names for readability\\n   - Used Kotlin\'s string templates\\n4. Assertions:\\n   - Imported from kotlin.test\\n   - Used Kotlin\'s assertThrows\\n5. Mocking:\\n   - Used mockito-kotlin extensions\\n   - Replaced when/thenReturn with whenever\\n6. Properties:\\n   - Converted to Kotlin property syntax\\n   - Used constructor parameter properties\\n7. Named Parameters:\\n   - Added for better readability\\n   - Especially in object creation\\n\\nVerification Steps:\\n```bash\\n# Compile and test\\n./gradlew :service:test --tests \\"com.example.service.UserServiceTest\\"\\n\\n# Test output\\n> Task :service:test\\nBUILD SUCCESSFUL in 3s\\n4 actionable tasks: 4 executed\\n```\\n\\nMigration Summary:\\n1. \u2705 Syntax converted to idiomatic Kotlin\\n2. \u2705 All tests passing\\n3. \u2705 Maintained test coverage\\n4. \u2705 Improved readability with Kotlin features\\n5. \u2705 Verified with Gradle build\\n\\nWould you like me to proceed with migrating the remaining test files?","extensions":[{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[]}]}')},60386:e=>{"use strict";e.exports=JSON.parse('{"id":"developer-jetbrains-java-upgrade","title":"Upgrade Java Project","description":"Upgrade Java project to latest LTS version and refactor using newer features","category":"technical","job":"engineering","example_prompt":"Using the JetBrains IDE tools, upgrade this project to use the latest Java LTS version and refactor the codebase to use newer Java features where beneficial.","example_result":"I\'ll help you upgrade the Java project to the latest LTS version (Java 21) and refactor the code. Here\'s the process:\\n\\n1. Project Configuration Updates:\\n\\n```xml\\n\x3c!-- pom.xml --\x3e\\n<properties>\\n    <java.version>21</java.version>\\n    <maven.compiler.source>${java.version}</maven.compiler.source>\\n    <maven.compiler.target>${java.version}</maven.compiler.target>\\n</properties>\\n```\\n\\n2. Example Refactoring - Before and After:\\n\\n```java\\n// Before: Java 8 style code\\npublic class OrderProcessor {\\n    private final List<Order> orders = new ArrayList<>();\\n    \\n    public Optional<Order> findOrder(String id) {\\n        return orders.stream()\\n            .filter(order -> order.getId().equals(id))\\n            .findFirst();\\n    }\\n    \\n    public Map<String, List<Order>> groupByCustomer() {\\n        Map<String, List<Order>> result = new HashMap<>();\\n        for (Order order : orders) {\\n            String customerId = order.getCustomerId();\\n            if (!result.containsKey(customerId)) {\\n                result.put(customerId, new ArrayList<>());\\n            }\\n            result.get(customerId).add(order);\\n        }\\n        return result;\\n    }\\n    \\n    public double calculateTotal(List<Order> orders) {\\n        double total = 0;\\n        for (Order order : orders) {\\n            total += order.getAmount();\\n        }\\n        return total;\\n    }\\n}\\n```\\n\\n```java\\n// After: Java 21 features\\npublic class OrderProcessor {\\n    private final List<Order> orders = new ArrayList<>();\\n    \\n    public Optional<Order> findOrder(String id) {\\n        return orders.stream()\\n            .filter(order -> order.id().equals(id))  // Record accessor\\n            .findFirst();\\n    }\\n    \\n    public Map<String, List<Order>> groupByCustomer() {\\n        return orders.stream()\\n            .collect(Collectors.groupingBy(Order::customerId));  // Method reference\\n    }\\n    \\n    public double calculateTotal(List<Order> orders) {\\n        return orders.stream()\\n            .mapToDouble(Order::amount)\\n            .sum();\\n    }\\n    \\n    // New pattern matching for switch\\n    public String getOrderStatus(Order order) {\\n        return switch (order.status()) {\\n            case PENDING when order.amount() > 1000 -> \\"High-value pending\\";\\n            case PENDING -> \\"Pending\\";\\n            case SHIPPED -> \\"Shipped\\";\\n            case DELIVERED -> \\"Delivered\\";\\n            case null -> throw new IllegalStateException(\\"Status cannot be null\\");\\n        };\\n    }\\n    \\n    // Records for DTOs\\n    public record Order(\\n        String id,\\n        String customerId,\\n        double amount,\\n        Status status\\n    ) {}\\n    \\n    public enum Status { PENDING, SHIPPED, DELIVERED }\\n    \\n    // Text blocks for SQL queries\\n    private static final String FIND_ORDERS_SQL = \\"\\"\\"\\n        SELECT o.id, o.customer_id, o.amount, o.status\\n        FROM orders o\\n        WHERE o.customer_id = ?\\n        AND o.status IN (?, ?)\\n        ORDER BY o.created_at DESC\\n        \\"\\"\\";\\n}\\n```\\n\\n3. Build Configuration Updates:\\n\\n```groovy\\n// build.gradle\\nplugins {\\n    id \'java\'\\n    id \'org.springframework.boot\' version \'3.2.0\'\\n}\\n\\njava {\\n    sourceCompatibility = JavaVersion.VERSION_21\\n    targetCompatibility = JavaVersion.VERSION_21\\n}\\n\\ndependencies {\\n    // Updated dependencies for Java 21\\n    implementation \'org.springframework.boot:spring-boot-starter:3.2.0\'\\n    testImplementation \'org.junit.jupiter:junit-jupiter:5.10.0\'\\n}\\n```\\n\\n4. IDE Configuration:\\n\\n```json\\n// .idea/misc.xml\\n{\\n  \\"project-jdk-name\\": \\"21\\",\\n  \\"project-jdk-type\\": \\"JavaSDK\\",\\n  \\"language-level\\": \\"21\\"\\n}\\n```\\n\\n5. Migration Report:\\n\\nFeatures Upgraded:\\n- Records for data classes\\n- Pattern matching for switch\\n- Text blocks for multiline strings\\n- Enhanced type inference\\n- Sealed classes where applicable\\n- Virtual threads for concurrent operations\\n\\nStatistics:\\n```\\nFiles Modified: 47\\nNew Features Used:\\n- Records: 12 classes converted\\n- Pattern Matching: 8 switch statements updated\\n- Text Blocks: 15 SQL queries converted\\n- Sealed Classes: 3 hierarchies implemented\\n- Virtual Threads: 2 executors updated\\n```\\n\\n6. Performance Impact:\\n```\\nBenchmark Results (JMH):\\n- Startup Time: -15%\\n- Memory Usage: -22%\\n- Response Time: -8%\\n- Throughput: +12%\\n```\\n\\n7. Verification Steps:\\n```bash\\n# Compile and test\\n./gradlew clean build\\n\\n# Run tests\\n./gradlew test\\n\\n# Check for Java 21 compatibility\\n./gradlew dependencyInsight --dependency java\\n```\\n\\nWould you like me to:\\n1. Show more refactoring examples?\\n2. Generate migration scripts?\\n3. Run compatibility tests?\\n4. Update CI/CD configurations?","extensions":[{"name":"JetBrains","command":"npx -y @jetbrains/mcp-proxy","is_builtin":false,"environmentVariables":[]},{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[]}]}')},65420:e=>{"use strict";e.exports=JSON.parse('{"id":"developer-js-express-setup","title":"Scaffold JavaScript Boilerplate","description":"Initialize a new JavaScript project with Express, Mongoose, Nodemon, and Dotenv","category":"technical","job":"engineering","example_prompt":"Set up a new JavaScript project with Express, Mongoose, Nodemon, and Dotenv. Fetch the latest package versions, generate a README with those versions, and initialize Git","example_result":"I\'ll help you set up a new JavaScript project with Express and related packages. Here\'s the step-by-step process:\\n\\n1. Initialize Project and Install Dependencies:\\n\\n```bash\\n# Initialize project\\nnpm init -y\\n\\n# Install dependencies\\nnpm install express@4.18.2 mongoose@8.0.3 dotenv@16.3.1\\nnpm install --save-dev nodemon@3.0.2\\n```\\n\\n2. Project Structure:\\n\\n```\\nproject-root/\\n\u251c\u2500\u2500 src/\\n\u2502   \u251c\u2500\u2500 config/\\n\u2502   \u2502   \u2514\u2500\u2500 database.js\\n\u2502   \u251c\u2500\u2500 models/\\n\u2502   \u2502   \u2514\u2500\u2500 User.js\\n\u2502   \u251c\u2500\u2500 routes/\\n\u2502   \u2502   \u2514\u2500\u2500 api.js\\n\u2502   \u251c\u2500\u2500 middleware/\\n\u2502   \u2502   \u2514\u2500\u2500 auth.js\\n\u2502   \u2514\u2500\u2500 app.js\\n\u251c\u2500\u2500 .env\\n\u251c\u2500\u2500 .gitignore\\n\u251c\u2500\u2500 package.json\\n\u2514\u2500\u2500 README.md\\n```\\n\\n3. Configuration Files:\\n\\n```javascript\\n// src/config/database.js\\nconst mongoose = require(\'mongoose\');\\n\\nconst connectDB = async () => {\\n  try {\\n    const conn = await mongoose.connect(process.env.MONGODB_URI, {\\n      useNewUrlParser: true,\\n      useUnifiedTopology: true\\n    });\\n    console.log(`MongoDB Connected: ${conn.connection.host}`);\\n  } catch (error) {\\n    console.error(`Error: ${error.message}`);\\n    process.exit(1);\\n  }\\n};\\n\\nmodule.exports = connectDB;\\n```\\n\\n4. Main Application File:\\n\\n```javascript\\n// src/app.js\\nrequire(\'dotenv\').config();\\nconst express = require(\'express\');\\nconst connectDB = require(\'./config/database\');\\n\\nconst app = express();\\n\\n// Connect to database\\nconnectDB();\\n\\n// Middleware\\napp.use(express.json());\\napp.use(express.urlencoded({ extended: true }));\\n\\n// Routes\\napp.use(\'/api\', require(\'./routes/api\'));\\n\\n// Error handling\\napp.use((err, req, res, next) => {\\n  console.error(err.stack);\\n  res.status(500).send(\'Something broke!\');\\n});\\n\\nconst PORT = process.env.PORT || 3000;\\napp.listen(PORT, () => {\\n  console.log(`Server is running on port ${PORT}`);\\n});\\n```\\n\\n5. Example Route and Model:\\n\\n```javascript\\n// src/models/User.js\\nconst mongoose = require(\'mongoose\');\\n\\nconst userSchema = new mongoose.Schema({\\n  username: {\\n    type: String,\\n    required: true,\\n    unique: true\\n  },\\n  email: {\\n    type: String,\\n    required: true,\\n    unique: true\\n  },\\n  createdAt: {\\n    type: Date,\\n    default: Date.now\\n  }\\n});\\n\\nmodule.exports = mongoose.model(\'User\', userSchema);\\n```\\n\\n```javascript\\n// src/routes/api.js\\nconst express = require(\'express\');\\nconst router = express.Router();\\nconst User = require(\'../models/User\');\\n\\nrouter.post(\'/users\', async (req, res) => {\\n  try {\\n    const user = new User(req.body);\\n    await user.save();\\n    res.status(201).json(user);\\n  } catch (error) {\\n    res.status(400).json({ error: error.message });\\n  }\\n});\\n\\nmodule.exports = router;\\n```\\n\\n6. Environment Configuration:\\n\\n```env\\n# .env\\nPORT=3000\\nMONGODB_URI=mongodb://localhost:27017/myapp\\nNODE_ENV=development\\n```\\n\\n7. Package.json Scripts:\\n\\n```json\\n{\\n  \\"name\\": \\"express-mongoose-starter\\",\\n  \\"version\\": \\"1.0.0\\",\\n  \\"scripts\\": {\\n    \\"start\\": \\"node src/app.js\\",\\n    \\"dev\\": \\"nodemon src/app.js\\",\\n    \\"test\\": \\"jest\\"\\n  },\\n  \\"dependencies\\": {\\n    \\"express\\": \\"^4.18.2\\",\\n    \\"mongoose\\": \\"^8.0.3\\",\\n    \\"dotenv\\": \\"^16.3.1\\"\\n  },\\n  \\"devDependencies\\": {\\n    \\"nodemon\\": \\"^3.0.2\\"\\n  }\\n}\\n```\\n\\n8. Git Configuration:\\n\\n```bash\\n# Initialize Git\\ngit init\\n\\n# Create .gitignore\\ncat > .gitignore << EOL\\nnode_modules/\\n.env\\n.DS_Store\\nEOL\\n\\n# Initial commit\\ngit add .\\ngit commit -m \\"Initial commit: Express project setup\\"\\n```\\n\\n9. README.md:\\n\\n```markdown\\n# Express Mongoose Starter\\n\\nA modern Express.js application with MongoDB integration.\\n\\n## Features\\n\\n- Express.js 4.18.2 web framework\\n- MongoDB integration with Mongoose 8.0.3\\n- Environment variable support with Dotenv 16.3.1\\n- Development server with Nodemon 3.0.2\\n- Structured project layout\\n- Basic error handling\\n- API route examples\\n\\n## Getting Started\\n\\n1. Clone the repository\\n2. Install dependencies: `npm install`\\n3. Create .env file with required variables\\n4. Start development server: `npm run dev`\\n\\n## Available Scripts\\n\\n- `npm start`: Production mode\\n- `npm run dev`: Development mode with hot reload\\n- `npm test`: Run tests\\n\\n## Project Structure\\n\\n[Project structure diagram as shown above]\\n\\n## API Endpoints\\n\\n- POST /api/users: Create new user\\n- [Add more endpoints as developed]\\n\\n## Environment Variables\\n\\n- PORT: Server port (default: 3000)\\n- MONGODB_URI: MongoDB connection string\\n- NODE_ENV: Environment mode\\n```\\n\\nThe project is now set up! Would you like me to:\\n1. Add authentication middleware?\\n2. Set up testing with Jest?\\n3. Add more API endpoints?\\n4. Configure CI/CD?","extensions":[{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[]}]}')},89476:e=>{"use strict";e.exports=JSON.parse('{"id":"voyp-make-call","title":"Make a Phone Call","description":"Have goose place a phone call","category":"productivity","job":"operations","featured":true,"example_prompt":"Please call the number [phone number] and tell a joke","example_result":"I\'ll help you make a phone call using VOYP. Here\'s what will happen:\\n\\n1. Call Initiation:\\n```\\nInitiating call to: +1 (XXX) XXX-XXXX\\nStatus: Connecting...\\n```\\n\\n2. Call Connected:\\n```\\nCall Status: Connected\\nDuration: 00:00:03\\n```\\n\\n3. Voice Interaction:\\n```\\nGoose: \\"Hi there! I\'ve got a programming joke for you:\\n\\nWhy do programmers always mix up Christmas and Halloween?\\n\\nBecause Oct 31 equals Dec 25!\\"\\n```\\n\\n4. Call Summary:\\n```\\nCall completed successfully\\n- Duration: 32 seconds\\n- Quality: Good\\n- Recording: Available at voyp://calls/2025/03/31/call_12345.mp3\\n```\\n\\nWould you like me to:\\n1. Make another call?\\n2. Tell a different joke?\\n3. Save the recording?\\n4. Schedule a follow-up call?","extensions":[{"name":"VOYP","command":"npx -y @voyp-mcp@0.1.0","is_builtin":false,"link":"https://github.com/paulotaylor/voyp-mcp","environmentVariables":[{"name":"VOYP_API_KEY","description":"Your VOYP API Key","required":true}]}]}')},33791:e=>{"use strict";e.exports=JSON.parse('{"id":"business-marketing-budget-review","title":"Marketing Budget Review Meeting Prep","description":"Prepare for marketing budget review meeting by analyzing Google Drive documents","category":"business","job":"marketing-content","example_prompt":"I have an important marketing budget review meeting in 30 minutes and I need your help getting prepared. I have several documents in my Google Drive from our previous meetings and planning sessions. Could you help me by:\\n\\n1. Finding all relevant documents about our marketing budget and performance\\n2. Giving me a quick summary of our Q1 performance\\n3. Highlighting the key decisions we need to make about the marketing automation tool and video production\\n4. Identifying any outstanding action items from our last meeting","example_result":"I\'ll help you prepare for your marketing budget review meeting. Here\'s what I found:\\n\\n## 1. Relevant Documents Located\\n\\n```\\nFound 4 relevant documents:\\n1. Q1_2025_Marketing_Budget_Report.xlsx\\n2. Marketing_Team_Meeting_Minutes_March15.docx\\n3. Marketing_Automation_Tool_Comparison.pdf\\n4. Video_Production_Quotes_2025.xlsx\\n```\\n\\n## 2. Q1 2025 Performance Summary\\n\\n```\\nBudget Overview:\\n- Total Budget: $250,000\\n- Spent: $228,500 (91.4%)\\n- Remaining: $21,500\\n\\nKey Metrics vs Targets:\\n\u2705 Lead Generation: 2,450 (Target: 2,000)\\n\u2705 Cost per Lead: $48 (Target: $55)\\n\u2705 Conversion Rate: 3.8% (Target: 3.5%)\\n\u274c Customer Acquisition Cost: $380 (Target: $350)\\n```\\n\\nChannel Performance:\\n```\\nPaid Search:\\n- Budget: $80,000\\n- Spent: $78,500\\n- ROI: 2.8x\\n\\nSocial Media:\\n- Budget: $60,000\\n- Spent: $55,000\\n- ROI: 3.2x\\n\\nContent Marketing:\\n- Budget: $45,000\\n- Spent: $42,000\\n- ROI: 2.5x\\n\\nEvents:\\n- Budget: $65,000\\n- Spent: $53,000\\n- ROI: 1.8x\\n```\\n\\n## 3. Key Decisions Needed\\n\\n### Marketing Automation Tool\\n```\\nOptions on the table:\\n1. HubSpot Enterprise\\n   - Cost: $38,000/year\\n   - Pros: Full integration, better reporting\\n   - Cons: Higher cost, migration needed\\n\\n2. Marketo\\n   - Cost: $29,000/year\\n   - Pros: Advanced features, good API\\n   - Cons: Steeper learning curve\\n\\n3. Current Tool + Upgrades\\n   - Cost: $22,000/year\\n   - Pros: No migration, team familiar\\n   - Cons: Missing key features\\n```\\n\\n### Video Production\\n```\\nProposals to consider:\\n1. In-house Team\\n   - Setup Cost: $45,000\\n   - Annual Cost: $120,000\\n   - Output: 8-10 videos/month\\n\\n2. Agency Partnership\\n   - Monthly Retainer: $8,500\\n   - Per Video: $2,000-$3,500\\n   - Output: 4-6 videos/month\\n\\n3. Hybrid Model\\n   - Basic in-house: $25,000\\n   - Agency support: $5,000/month\\n   - Output: 6-8 videos/month\\n```\\n\\n## 4. Outstanding Action Items\\n\\nFrom March 15th Meeting:\\n```\\nUrgent (Due This Week):\\n1. \u23f0 Submit Q2 budget revision by Wednesday\\n2. \u23f0 Finalize marketing automation vendor shortlist\\n\\nHigh Priority:\\n3. \ud83d\udcca Complete ROI analysis for video production options\\n4. \ud83d\udcc8 Update campaign tracking for new privacy requirements\\n\\nPending Decisions:\\n5. \ud83e\udd1d Agency contract renewal (due in 45 days)\\n6. \ud83d\udcb0 Budget reallocation for Q2 events\\n```\\n\\n## Meeting Preparation Tips\\n\\n1. Key Discussion Points:\\n```\\n- Q1 overspend in paid search (-$3,500)\\n- Successful social media experiments (+15% engagement)\\n- Event budget underutilization (opportunity for reallocation)\\n- Marketing automation tool ROI projections\\n```\\n\\n2. Supporting Data to Reference:\\n```\\n- Lead quality scores by channel\\n- Automation tool comparison matrix\\n- Video production cost-benefit analysis\\n- Updated marketing team structure\\n```\\n\\n3. Recommended Agenda:\\n```\\n1. Q1 Performance Review (15 mins)\\n2. Marketing Automation Decision (20 mins)\\n3. Video Production Strategy (15 mins)\\n4. Q2 Budget Adjustments (10 mins)\\n```\\n\\nWould you like me to:\\n1. Create a presentation with these key points?\\n2. Generate a detailed cost comparison?\\n3. Draft follow-up action items?\\n4. Set up calendar reminders for deadlines?","extensions":[{"name":"Google Drive","command":"npx -y @modelcontextprotocol/server-gdrive","is_builtin":false,"link":"https://block.github.io/goose/v1/extensions/google-drive","environmentVariables":[{"name":"GDRIVE_OAUTH_PATH","description":"/Users/<username>/.config/gcp-oauth.keys.json / ","required":true},{"name":"GDRIVE_CREDENTIALS_PATH","description":"/Users/<username>/.config/.gdrive-server-credentials.json /","required":true}]},{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[]}]}')},91122:e=>{"use strict";e.exports=JSON.parse('{"id":"multi-project-security-audit","title":"Multi-Project Security Audit","description":"Perform comprehensive security analysis across multiple projects to identify and fix vulnerabilities","category":"technical","job":"engineering","example_prompt":"Please analyze these codebases for security issues:\\n\\n1. Project Directories:\\n- [Directory Path 1]\\n- [Directory Path 2]\\n- [Directory Path 3]\\n\\n2. Look for:\\n- Hardcoded credentials (API keys, passwords, secrets)\\n- Insecure cryptographic practices\\n- SQL injection vulnerabilities\\n- Exposed configuration files\\n- Insecure session handling\\n- Logging of sensitive data\\n- Outdated dependencies\\n- Unsafe authentication methods\\n\\n3. For each vulnerability found:\\n- Show the problematic code\\n- Explain the security risk\\n- Provide a secure implementation\\n- Help apply and test the fixes\\n\\n4. Create a detailed security report including:\\n- Critical findings by project\\n- Risk severity levels\\n- File locations and snippets\\n- Applied fixes and improvements\\n- Verification steps taken","example_result":"# Security Audit Report\\n\\n## Executive Summary\\n\\nAudit completed across 3 projects. Found:\\n- 4 Critical vulnerabilities\\n- 7 High-risk issues\\n- 12 Medium-risk issues\\n- 8 Low-risk concerns\\n\\n## Project 1: E-commerce API\\n\\n### Critical Findings\\n\\n1. Hardcoded AWS Credentials\\n```python\\n# /app/config/aws.py - Line 23\\n# VULNERABLE CODE\\naws_access_key = \'AKIA1234567890ABCDEF\'\\naws_secret_key = \'abcd1234EFGH5678ijkl9012mnop3456QRST7890\'\\n\\n# SECURE IMPLEMENTATION\\naws_access_key = os.environ.get(\'AWS_ACCESS_KEY\')\\naws_secret_key = os.environ.get(\'AWS_SECRET_KEY\')\\n\\nif not all([aws_access_key, aws_secret_key]):\\n    raise ConfigurationError(\'AWS credentials not properly configured\')\\n```\\n\\nRisk: Critical\\n- Exposed credentials in version control\\n- Potential unauthorized AWS access\\n- Financial and data security implications\\n\\nFix Applied:\\n```bash\\n# 1. Removed credentials from code\\n# 2. Added to environment variables\\n# 3. Updated deployment configurations\\n# 4. Rotated AWS keys\\n```\\n\\n2. SQL Injection Vulnerability\\n```python\\n# /app/models/user.py - Line 156\\n# VULNERABLE CODE\\ndef find_by_username(username):\\n    query = f\\"SELECT * FROM users WHERE username = \'{username}\'\\"\\n    return db.execute(query)\\n\\n# SECURE IMPLEMENTATION\\ndef find_by_username(username):\\n    query = \\"SELECT * FROM users WHERE username = %s\\"\\n    return db.execute(query, (username,))\\n```\\n\\nRisk: Critical\\n- SQL injection possible\\n- Potential data breach\\n- Unauthorized data access\\n\\n## Project 2: Admin Dashboard\\n\\n### High Risk Findings\\n\\n1. Insecure Session Configuration\\n```javascript\\n// /src/config/session.js - Line 45\\n// VULNERABLE CODE\\napp.use(session({\\n  secret: \'my-secret-key\',\\n  resave: true,\\n  saveUninitialized: true,\\n  cookie: { secure: false }\\n}));\\n\\n// SECURE IMPLEMENTATION\\napp.use(session({\\n  secret: process.env.SESSION_SECRET,\\n  resave: false,\\n  saveUninitialized: false,\\n  cookie: {\\n    secure: process.env.NODE_ENV === \'production\',\\n    httpOnly: true,\\n    sameSite: \'strict\',\\n    maxAge: 3600000 // 1 hour\\n  }\\n}));\\n```\\n\\n2. Outdated Dependencies\\n```json\\n// package.json\\n{\\n  \\"dependencies\\": {\\n    \\"express\\": \\"4.16.1\\",        // Vulnerable version\\n    \\"moment\\": \\"2.24.0\\",         // Known security issues\\n    \\"lodash\\": \\"4.17.15\\"        // Multiple CVEs\\n  }\\n}\\n```\\n\\nUpdated to:\\n```json\\n{\\n  \\"dependencies\\": {\\n    \\"express\\": \\"4.18.2\\",\\n    \\"moment\\": \\"2.29.4\\",\\n    \\"lodash\\": \\"4.17.21\\"\\n  }\\n}\\n```\\n\\n## Project 3: Mobile API\\n\\n### High Risk Findings\\n\\n1. Insecure Password Hashing\\n```java\\n// /src/main/java/com/example/auth/PasswordUtil.java\\n// VULNERABLE CODE\\npublic String hashPassword(String password) {\\n    return DigestUtils.md5Hex(password);\\n}\\n\\n// SECURE IMPLEMENTATION\\npublic String hashPassword(String password) {\\n    return BCrypt.hashpw(password, BCrypt.gensalt(12));\\n}\\n```\\n\\n2. Sensitive Data Exposure\\n```java\\n// /src/main/java/com/example/logging/AuditLogger.java\\n// VULNERABLE CODE\\nlogger.info(\\"User login: \\" + username + \\", password: \\" + password);\\n\\n// SECURE IMPLEMENTATION\\nlogger.info(\\"User login attempt: {}\\" username);\\n```\\n\\n## Applied Security Improvements\\n\\n1. Dependency Updates\\n```bash\\n# Updated all projects to use latest secure versions\\nnpm audit fix\\ncomposer update\\nmvn versions:use-latest-versions\\n```\\n\\n2. Security Headers\\n```javascript\\n// Added security headers to all projects\\napp.use(helmet());\\napp.use(hpp());\\napp.use(cors(corsOptions));\\n```\\n\\n3. Input Validation\\n```python\\n# Added request validation\\nfrom marshmallow import Schema, fields\\n\\nclass UserSchema(Schema):\\n    username = fields.Str(required=True, validate=validate.Length(min=3))\\n    email = fields.Email(required=True)\\n```\\n\\n## Verification Steps\\n\\n1. Automated Testing\\n```bash\\n# Run security scans\\nnpm audit\\nbandit -r .\\nSonarQube analysis\\n\\n# Run penetration tests\\nOWASP ZAP scan\\nBurp Suite tests\\n```\\n\\n2. Manual Testing\\n```\\n\u2713 SQL injection attempts\\n\u2713 XSS payload testing\\n\u2713 CSRF token verification\\n\u2713 Session handling checks\\n\u2713 Password policy enforcement\\n```\\n\\n## Recommendations\\n\\n1. Immediate Actions:\\n```\\n- Rotate all exposed credentials\\n- Update vulnerable dependencies\\n- Enable WAF rules\\n- Implement security headers\\n```\\n\\n2. Short-term Improvements:\\n```\\n- Set up automated security scanning\\n- Implement SAST/DAST in CI/CD\\n- Add security test cases\\n- Update security documentation\\n```\\n\\n3. Long-term Strategy:\\n```\\n- Regular security training\\n- Quarterly security audits\\n- Threat modeling for new features\\n- Bug bounty program\\n```\\n\\nWould you like me to:\\n1. Generate security patches?\\n2. Create Jira tickets?\\n3. Update security documentation?\\n4. Schedule follow-up review?","extensions":[{"name":"Filesystem","command":"npx -y @modelcontextprotocol/server-filesystem","is_builtin":false,"environmentVariables":[]},{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[]}]}')},41179:e=>{"use strict";e.exports=JSON.parse('{"id":"data-name-column-split","title":"Clean Spreadsheet Data","description":"Automatically organize messy data by splitting and reformatting columns","category":"productivity","job":"data-analytics","example_prompt":"I\'ll help you split the names in Column C into separate First Name and Last Name columns. Let me analyze and modify your spreadsheet:\\n\\n1. First, I\'ll check the current structure of your spreadsheet\\n2. Then I\'ll create a script to:\\n   - Read the full names from Column C\\n   - Split each name into first and last components\\n   - Keep the first name in Column C\\n   - Add the last names in Column D\\n3. Finally, I\'ll save the changes back to your file\\n\\nPlease provide the path to your Excel file and I\'ll help you split the names.","example_result":"I\'ve analyzed your spreadsheet and will help split the names. Here\'s what I found and what I\'ll do:\\n\\n1. Current Structure Analysis:\\n```\\nSheet: Customer Data\\nColumn C (Full Name): Contains 458 rows of data\\nSample values:\\n- John Smith\\n- Mary Jane Wilson\\n- Robert J. Anderson\\n- Sarah Jean-Baptiste\\n- O\'Connor, Patrick\\n```\\n\\n2. Data Cleaning Script:\\n\\n```python\\nimport pandas as pd\\n\\ndef clean_and_split_names(df):\\n    # Copy original data\\n    df[\'Original Name\'] = df[\'Full Name\']\\n    \\n    # Handle reversed names (Last, First)\\n    df[\'Full Name\'] = df[\'Full Name\'].apply(lambda x: \\n        \' \'.join(reversed(x.split(\', \'))) if \',\' in x else x)\\n    \\n    # Split names into components\\n    def split_name(name):\\n        parts = name.split()\\n        if len(parts) == 1:\\n            return [parts[0], \'\']\\n        elif len(parts) == 2:\\n            return parts\\n        else:\\n            # Handle middle names/initials\\n            return [parts[0], \' \'.join(parts[1:])]\\n    \\n    # Apply splitting\\n    df[[\'First Name\', \'Last Name\']] = pd.DataFrame(\\n        df[\'Full Name\'].apply(split_name).tolist(), \\n        index=df.index\\n    )\\n    \\n    return df\\n\\n# Read Excel file\\ndf = pd.read_excel(\'customer_data.xlsx\')\\n\\n# Process names\\ndf = clean_and_split_names(df)\\n\\n# Save changes\\ndf.to_excel(\'customer_data_updated.xlsx\', index=False)\\n```\\n\\n3. Results Summary:\\n```\\nProcessed 458 names:\\n- Successfully split: 445\\n- Special cases handled: 13\\n  - Hyphenated surnames: 4\\n  - Multiple surnames: 6\\n  - Single names: 2\\n  - Reversed format: 1\\n```\\n\\n4. Sample Results:\\n```\\nBefore | After\\n-------|-----------------------------------------------\\nFull Name | First Name | Last Name | Original Name\\n----------|------------|-----------|---------------\\nJohn Smith | John | Smith | John Smith\\nMary Jane Wilson | Mary | Jane Wilson | Mary Jane Wilson\\nRobert J. Anderson | Robert | J. Anderson | Robert J. Anderson\\nSarah Jean-Baptiste | Sarah | Jean-Baptiste | Sarah Jean-Baptiste\\nO\'Connor, Patrick | Patrick | O\'Connor | O\'Connor, Patrick\\n```\\n\\n5. Data Quality Checks:\\n```\\n\u2713 No empty cells created\\n\u2713 Special characters preserved\\n\u2713 Original data backed up\\n\u2713 Formatting maintained\\n\u2713 Column headers properly set\\n```\\n\\n6. File Updates:\\n```\\n1. Added new columns:\\n   - Column C: First Name\\n   - Column D: Last Name\\n   - Column E: Original Name (backup)\\n\\n2. Updated column headers\\n3. Applied consistent formatting\\n4. Added data validation\\n```\\n\\nWould you like me to:\\n1. Show more sample rows?\\n2. Handle any special cases differently?\\n3. Add additional data cleaning rules?\\n4. Create a backup before saving?","extensions":[{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[]},{"name":"Google Drive","command":"npx -y @modelcontextprotocol/server-gdrive","is_builtin":false,"environmentVariables":[{"name":"GDRIVE_OAUTH_PATH","description":"/Users/<username>/.config/gcp-oauth.keys.json / ","required":true},{"name":"GDRIVE_CREDENTIALS_PATH","description":"/Users/<username>/.config/.gdrive-server-credentials.json /","required":true}]}]}')},95361:e=>{"use strict";e.exports=JSON.parse('{"id":"developer-review-prep","title":"Structure Your Performance Review","description":"Sort collected feedback into a well-organized performance review","category":"business","job":"project-management","example_prompt":"Create a web app that will take feedback and sort it into custom performance dimensions to populate a performance evaluation. The app should:\\n- Allow users to define their review dimensions (e.g., Leadership, Technical Skills, Innovation)\\n- Accept feedback text through input or file upload\\n- Sort feedback into the defined dimensions\\n- Export the organized feedback for performance reviews","example_result":"I\'ll help you create a performance review organization app. Here\'s the implementation:\\n\\n1. Frontend Implementation (React):\\n\\n```jsx\\n// src/components/ReviewOrganizer.js\\nimport React, { useState } from \'react\';\\nimport { TextField, Button, Card, Chip } from \'@mui/material\';\\n\\nconst ReviewOrganizer = () => {\\n  const [dimensions, setDimensions] = useState([\\n    { id: 1, name: \'Leadership\' },\\n    { id: 2, name: \'Technical Skills\' },\\n    { id: 3, name: \'Innovation\' }\\n  ]);\\n\\n  const [feedback, setFeedback] = useState(\'\');\\n  const [organizedFeedback, setOrganizedFeedback] = useState({});\\n\\n  return (\\n    <div className=\\"p-6\\">\\n      <h1 className=\\"text-2xl mb-4\\">Performance Review Organizer</h1>\\n      \\n      {/* Dimension Management */}\\n      <section className=\\"mb-6\\">\\n        <h2 className=\\"text-xl mb-2\\">Review Dimensions</h2>\\n        <div className=\\"flex flex-wrap gap-2\\">\\n          {dimensions.map(dim => (\\n            <Chip\\n              key={dim.id}\\n              label={dim.name}\\n              onDelete={() => handleDeleteDimension(dim.id)}\\n              className=\\"m-1\\"\\n            />\\n          ))}\\n          <Button\\n            variant=\\"outlined\\"\\n            onClick={() => setShowDimensionDialog(true)}\\n          >\\n            Add Dimension\\n          </Button>\\n        </div>\\n      </section>\\n\\n      {/* Feedback Input */}\\n      <section className=\\"mb-6\\">\\n        <h2 className=\\"text-xl mb-2\\">Input Feedback</h2>\\n        <TextField\\n          multiline\\n          rows={4}\\n          fullWidth\\n          value={feedback}\\n          onChange={(e) => setFeedback(e.target.value)}\\n          placeholder=\\"Paste feedback text here...\\"\\n        />\\n        <input\\n          type=\\"file\\"\\n          accept=\\".txt,.doc,.docx\\"\\n          onChange={handleFileUpload}\\n          className=\\"mt-2\\"\\n        />\\n      </section>\\n\\n      {/* Organized Feedback */}\\n      <section>\\n        <h2 className=\\"text-xl mb-2\\">Organized Feedback</h2>\\n        {dimensions.map(dim => (\\n          <Card key={dim.id} className=\\"p-4 mb-4\\">\\n            <h3 className=\\"font-bold mb-2\\">{dim.name}</h3>\\n            <ul className=\\"list-disc pl-4\\">\\n              {organizedFeedback[dim.id]?.map((item, i) => (\\n                <li key={i} className=\\"mb-2\\">{item}</li>\\n              ))}\\n            </ul>\\n          </Card>\\n        ))}\\n      </section>\\n\\n      <Button\\n        variant=\\"contained\\"\\n        color=\\"primary\\"\\n        onClick={handleExport}\\n        className=\\"mt-4\\"\\n      >\\n        Export Review\\n      </Button>\\n    </div>\\n  );\\n};\\n```\\n\\n2. Backend Implementation (Node.js/Express):\\n\\n```javascript\\n// src/server/feedbackAnalyzer.js\\nconst natural = require(\'natural\');\\nconst classifier = new natural.BayesClassifier();\\n\\nclass FeedbackAnalyzer {\\n  constructor(dimensions) {\\n    this.dimensions = dimensions;\\n    this.trainClassifier();\\n  }\\n\\n  trainClassifier() {\\n    // Training data for each dimension\\n    const trainingData = {\\n      Leadership: [\\n        \'leads by example\',\\n        \'motivates team\',\\n        \'decision making\',\\n        \'delegation\',\\n        \'team management\'\\n      ],\\n      \'Technical Skills\': [\\n        \'problem solving\',\\n        \'code quality\',\\n        \'technical knowledge\',\\n        \'debugging\',\\n        \'architecture\'\\n      ],\\n      Innovation: [\\n        \'creative solutions\',\\n        \'new ideas\',\\n        \'process improvement\',\\n        \'initiative\',\\n        \'experimentation\'\\n      ]\\n    };\\n\\n    // Train classifier with examples\\n    Object.entries(trainingData).forEach(([dimension, examples]) => {\\n      examples.forEach(example => {\\n        classifier.addDocument(example, dimension);\\n      });\\n    });\\n\\n    classifier.train();\\n  }\\n\\n  analyzeFeedback(feedback) {\\n    // Split feedback into sentences\\n    const sentences = feedback.match(/[^.!?]+[.!?]+/g) || [feedback];\\n\\n    // Categorize each sentence\\n    const categorized = {};\\n    this.dimensions.forEach(dim => {\\n      categorized[dim.id] = [];\\n    });\\n\\n    sentences.forEach(sentence => {\\n      const dimension = classifier.classify(sentence);\\n      const dimId = this.dimensions.find(d => d.name === dimension)?.id;\\n      if (dimId) {\\n        categorized[dimId].push(sentence.trim());\\n      }\\n    });\\n\\n    return categorized;\\n  }\\n}\\n```\\n\\n3. Export Template:\\n\\n```markdown\\n# Performance Review Summary\\nDate: {{date}}\\nReviewer: {{reviewer}}\\n\\n## Leadership\\n{{#leadership}}\\n- {{.}}\\n{{/leadership}}\\n\\n## Technical Skills\\n{{#technical}}\\n- {{.}}\\n{{/technical}}\\n\\n## Innovation\\n{{#innovation}}\\n- {{.}}\\n{{/innovation}}\\n\\n## Additional Notes\\n{{notes}}\\n\\n## Development Plan\\n1. Areas of Excellence:\\n   {{#excellence}}\\n   - {{.}}\\n   {{/excellence}}\\n\\n2. Areas for Growth:\\n   {{#growth}}\\n   - {{.}}\\n   {{/growth}}\\n\\n3. Action Items:\\n   {{#actions}}\\n   - {{.}}\\n   {{/actions}}\\n```\\n\\n4. Sample Usage:\\n\\nInput Feedback:\\n```\\nSarah has shown excellent leadership in the recent cloud migration project. \\nShe effectively managed team resources and deadlines. Her technical \\nknowledge of AWS services is impressive, and she implemented several \\ninnovative solutions to reduce costs. Team members appreciate her clear \\ncommunication and mentoring. She introduced a new CI/CD process that \\nimproved deployment efficiency by 40%.\\n```\\n\\nOrganized Output:\\n```\\nLeadership:\\n- Effectively managed team resources and deadlines\\n- Team members appreciate her clear communication and mentoring\\n\\nTechnical Skills:\\n- Technical knowledge of AWS services is impressive\\n- Implemented CI/CD process improving deployment efficiency\\n\\nInnovation:\\n- Implemented several innovative solutions to reduce costs\\n- Introduced new CI/CD process with 40% efficiency improvement\\n```\\n\\n5. Features:\\n\\n```\\n\u2713 Custom dimensions\\n\u2713 Bulk text processing\\n\u2713 File upload support\\n\u2713 Natural language processing\\n\u2713 Export to multiple formats\\n\u2713 Data persistence\\n\u2713 Multi-user support\\n```\\n\\nWould you like me to:\\n1. Add more training data?\\n2. Implement additional export formats?\\n3. Add collaborative features?\\n4. Create automated reminders?","extensions":[{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[]},{"name":"Google Drive","command":"npx -y @modelcontextprotocol/server-gdrive","is_builtin":false,"environmentVariables":[{"name":"GDRIVE_OAUTH_PATH","description":"/Users/<username>/.config/gcp-oauth.keys.json / ","required":true},{"name":"GDRIVE_CREDENTIALS_PATH","description":"/Users/<username>/.config/.gdrive-server-credentials.json /","required":true}]}]}')},21400:e=>{"use strict";e.exports=JSON.parse('{"id":"pieces-stand-up-status-report","title":"Create a status report for a stand-up meeting","description":"Create a status report for a stand-up meeting, including 5 bullet points for what was accomplished yesterday. This is using the Pieces Long-Term Memory.","category":"productivity","job":"project-management","example_prompt":"I need a status update for what I was using yesterday. Create a report with 5 bullet points based off the most important activities, and give each one a brief description.","example_result":"Here\'s a report summarizing your key activities from yesterday, based on the most important interactions and applications you were using:\\n\\n1. Code Development with Goose:\\n\\tActivity: You worked on integrating SSE MCP servers into the Goose CLI, making enhancements to handle extensions via schema URLs.\\n\\tDescription: This task involved modifying code and testing new integrations to support advanced functionalities. It also included interactions with the Goose community on Discord for feedback and troubleshooting.\\n\\n2. Documentation Updates:\\n\\tActivity: You updated and managed documentation related to the Goose project and MCP integrations.\\n\\tDescription: This involved preparing documentation for new features, including usage guidelines and technical details, aiding in the improvement of user experience and technical instructions.\\n\\n3. Community Interaction on Discord:\\n\\tActivity: Engaged with the Block Open Source Community to discuss project developments and potential collaborations.\\n\\tDescription: You actively participated in community discussions, exchanging insights on project enhancements, and exploring collaborative opportunities with other developers and contributors.\\n\\n4. Managing and Testing Extensions:\\n\\tActivity: You focused on testing and managing various extensions through the Goose platform.\\n\\tDescription: This included configuring and validating different extensions, ensuring their compatibility and functionality, and incorporating feedback from testing.\\n\\n5. Content and Integration Planning:\\n\\tActivity: Planned integration workflows for MCP and documented their use cases.\\n\\tDescription: You worked on strategies for implementing MCP integrations effectively, involving planning sessions to optimize future project deployments and align them with user requirements and project objectives.\\n\\nThese activities demonstrate a productive day with a focus on development, collaboration, and content management within your technical community.","extensions":[{"name":"Pieces","url":"http://localhost:39300/model_context_protocol/2024-11-05/sse","is_builtin":false}]}')},57844:e=>{"use strict";e.exports=JSON.parse('{"id":"sales-product-region-lookup","title":"Check Product Availability in Regions","description":"Research which countries and regions a product is available in","category":"business","job":"project-management","featured":true,"example_prompt":"List ISO 3166-1 country codes where {product_name} is sold. Return JSON containing:\\ncountry_codes: List of the ISO-3166-1 country codes that are valid for this device\\ndevice_model: The model you have performed the lookup for\\nis_north_america: Whether or not the specified device is expected to acquired easily in north america","example_result":"I\'ve researched the regional availability for iPhone 14 Pro. Here\'s the analysis:\\n\\n```json\\n{\\n  \\"device_model\\": \\"iPhone 14 Pro\\",\\n  \\"country_codes\\": [\\n    \\"AE\\", \\"AT\\", \\"AU\\", \\"BE\\", \\"BG\\", \\"BR\\", \\"CA\\", \\"CH\\", \\"CL\\", \\"CN\\",\\n    \\"CO\\", \\"CY\\", \\"CZ\\", \\"DE\\", \\"DK\\", \\"EE\\", \\"ES\\", \\"FI\\", \\"FR\\", \\"GB\\",\\n    \\"GR\\", \\"HK\\", \\"HR\\", \\"HU\\", \\"ID\\", \\"IE\\", \\"IL\\", \\"IN\\", \\"IT\\", \\"JP\\",\\n    \\"KR\\", \\"LT\\", \\"LU\\", \\"LV\\", \\"MX\\", \\"MY\\", \\"NL\\", \\"NO\\", \\"NZ\\", \\"PH\\",\\n    \\"PL\\", \\"PT\\", \\"RO\\", \\"SA\\", \\"SE\\", \\"SG\\", \\"SI\\", \\"SK\\", \\"TH\\", \\"TR\\",\\n    \\"TW\\", \\"US\\", \\"VN\\", \\"ZA\\"\\n  ],\\n  \\"is_north_america\\": true,\\n  \\"regional_details\\": {\\n    \\"north_america\\": {\\n      \\"countries\\": [\\"US\\", \\"CA\\", \\"MX\\"],\\n      \\"availability\\": \\"Full availability\\",\\n      \\"warranty_support\\": true,\\n      \\"carrier_support\\": true\\n    },\\n    \\"europe\\": {\\n      \\"countries\\": [\\"GB\\", \\"DE\\", \\"FR\\", \\"IT\\", \\"ES\\", \\"NL\\", \\"BE\\", \\"CH\\", \\"AT\\"],\\n      \\"availability\\": \\"Full availability\\",\\n      \\"warranty_support\\": true,\\n      \\"carrier_support\\": true\\n    },\\n    \\"asia_pacific\\": {\\n      \\"countries\\": [\\"JP\\", \\"KR\\", \\"CN\\", \\"HK\\", \\"SG\\", \\"AU\\"],\\n      \\"availability\\": \\"Full availability\\",\\n      \\"warranty_support\\": true,\\n      \\"carrier_support\\": true\\n    }\\n  },\\n  \\"model_variants\\": {\\n    \\"A2650\\": [\\"US\\", \\"CA\\"],\\n    \\"A2651\\": [\\"CN\\"],\\n    \\"A2652\\": [\\"JP\\"],\\n    \\"A2653\\": [\\"Global\\"]\\n  },\\n  \\"network_compatibility\\": {\\n    \\"5G\\": [\\"US\\", \\"CA\\", \\"JP\\", \\"KR\\", \\"CN\\", \\"GB\\", \\"DE\\", \\"FR\\"],\\n    \\"4G_LTE\\": \\"All listed countries\\",\\n    \\"3G\\": \\"Limited availability\\"\\n  },\\n  \\"purchase_channels\\": {\\n    \\"apple_store\\": \\"All listed countries\\",\\n    \\"carriers\\": \\"Major markets\\",\\n    \\"authorized_resellers\\": \\"All listed countries\\"\\n  },\\n  \\"import_restrictions\\": [\\n    \\"Some features may be restricted in certain regions\\",\\n    \\"Warranty service limited to country of purchase\\",\\n    \\"5G connectivity subject to carrier support\\"\\n  ]\\n}\\n```\\n\\nAdditional Notes:\\n1. Availability Status:\\n   - Full availability in 54 countries\\n   - Primary markets have immediate availability\\n   - Some markets may have limited stock\\n\\n2. Regional Variations:\\n   - Different model numbers by region\\n   - Feature availability varies by country\\n   - Warranty coverage region-specific\\n\\n3. Purchase Considerations:\\n   - Local warranty support\\n   - Carrier compatibility\\n   - Import regulations\\n\\nWould you like me to:\\n1. Check specific country availability?\\n2. Compare with other models?\\n3. Show carrier compatibility?\\n4. List region-specific features?","extensions":[{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[{"name":"product_name","description":"The name/model of the product to look up regional availability for","required":true}]}]}')},43596:e=>{"use strict";e.exports=JSON.parse("{\"id\":\"dev-query-optimization\",\"title\":\"Optimize Database Query Performance\",\"description\":\"Refactor a Ruby query to improve database performance by moving operations from memory to SQL\",\"category\":\"technical\",\"job\":\"data-analytics\",\"example_prompt\":\"The list_records method in app/services/record_service.rb has an issue causing the query to prematurely execute and perform operations in memory causing performance issues. Please refactor the query to build the entire query up in SQL so it can be performed with a single invocation and skip the work in memory.\",\"example_result\":\"I'll help optimize the database query. Here's the analysis and refactoring:\\n\\nOriginal Code (with performance issues):\\n```ruby\\n# app/services/record_service.rb\\nclass RecordService\\n  def list_records(filters = {})\\n    # Initial query that executes immediately\\n    records = Record.includes(:user, :category)\\n      .where(status: 'active')\\n      .order(created_at: :desc)\\n\\n    # Memory-intensive operations\\n    records = records.select { |r| r.user.subscribed? } if filters[:subscribed_only]\\n    records = records.select { |r| r.category.featured? } if filters[:featured_categories]\\n    records = records.select { |r| r.created_at >= 30.days.ago } if filters[:recent]\\n\\n    # More filtering in memory\\n    if filters[:min_value]\\n      records = records.select { |r| r.calculated_value >= filters[:min_value] }\\n    end\\n\\n    # Final memory operations\\n    records.map do |record|\\n      {\\n        id: record.id,\\n        title: record.title,\\n        user_name: record.user.name,\\n        category_name: record.category.name,\\n        value: record.calculated_value\\n      }\\n    end\\n  end\\nend\\n```\\n\\nOptimized Code:\\n```ruby\\n# app/services/record_service.rb\\nclass RecordService\\n  def list_records(filters = {})\\n    # Build query incrementally without executing\\n    records = Record\\n      .select(\\n        'records.id',\\n        'records.title',\\n        'records.created_at',\\n        'users.name AS user_name',\\n        'categories.name AS category_name',\\n        'COALESCE(records.base_value * multiplier.value, records.base_value) AS calculated_value'\\n      )\\n      .joins(:user, :category)\\n      .joins(\\n        'LEFT JOIN value_multipliers AS multiplier ON '\\n        'multiplier.record_type = records.type AND '\\n        'multiplier.valid_from <= CURRENT_TIMESTAMP'\\n      )\\n      .where(status: 'active')\\n\\n    # Add filters as SQL conditions\\n    records = records.where('users.subscription_status = ?', 'active') if filters[:subscribed_only]\\n    records = records.where('categories.featured = ?', true) if filters[:featured_categories]\\n    records = records.where('records.created_at >= ?', 30.days.ago) if filters[:recent]\\n    \\n    if filters[:min_value]\\n      records = records.where(\\n        'COALESCE(records.base_value * multiplier.value, records.base_value) >= ?',\\n        filters[:min_value]\\n      )\\n    end\\n\\n    # Add final ordering and execute query once\\n    records\\n      .order(created_at: :desc)\\n      .map do |record|\\n        {\\n          id: record.id,\\n          title: record.title,\\n          user_name: record.user_name,\\n          category_name: record.category_name,\\n          value: record.calculated_value\\n        }\\n      end\\n  end\\n\\n  private\\n\\n  def build_value_calculation\\n    # Complex value calculation moved to SQL\\n    <<~SQL\\n      CASE\\n        WHEN records.type = 'Premium' THEN base_value * 1.5\\n        WHEN records.type = 'Standard' THEN base_value * 1.2\\n        ELSE base_value\\n      END\\n    SQL\\n  end\\nend\\n```\\n\\nKey Optimizations:\\n\\n1. Eager Loading:\\n```ruby\\n# Before: Separate queries for associations\\n.includes(:user, :category)\\n\\n# After: Single JOIN query\\n.joins(:user, :category)\\n```\\n\\n2. SQL vs Memory Filtering:\\n```ruby\\n# Before: Memory filtering\\nrecords.select { |r| r.user.subscribed? }\\n\\n# After: SQL filtering\\n.where('users.subscription_status = ?', 'active')\\n```\\n\\n3. Calculated Values:\\n```ruby\\n# Before: Ruby calculation\\nrecord.calculated_value\\n\\n# After: SQL calculation\\nCOALESCE(records.base_value * multiplier.value, records.base_value) AS calculated_value\\n```\\n\\n4. Select Specific Fields:\\n```ruby\\n# Before: Loading entire records\\nRecord.includes(:user, :category)\\n\\n# After: Loading only needed fields\\n.select(\\n  'records.id',\\n  'records.title',\\n  'users.name AS user_name'\\n)\\n```\\n\\nPerformance Impact:\\n```\\nBefore:\\n- Query Time: 2.3 seconds\\n- Memory Usage: 1.2 GB\\n- Database Calls: 15\\n\\nAfter:\\n- Query Time: 180ms (87% faster)\\n- Memory Usage: 45 MB (96% reduction)\\n- Database Calls: 1\\n```\\n\\nMonitoring Results:\\n```sql\\nEXPLAIN ANALYZE SELECT ...\\n\\n-> Index Scan using records_created_at_idx  (cost=0.29..8.29 rows=500)\\n-> Hash Join  (cost=1.05..13.85 rows=487)\\n   -> Index Scan using users_subscription_idx  (cost=0.28..4.28 rows=95)\\n   -> Hash  (cost=0.77..0.77 rows=487)\\n```\\n\\nWould you like me to:\\n1. Add database indexes?\\n2. Implement caching?\\n3. Add query monitoring?\\n4. Write performance tests?\",\"extensions\":[{\"name\":\"Developer\",\"command\":\"developer\",\"is_builtin\":true,\"environmentVariables\":[]}]}")},48766:e=>{"use strict";e.exports=JSON.parse('{"id":"legal-regulatory-comparison","title":"Regulatory Document Change Analysis","description":"Run a comparative analysis between different versions of AML regulatory documents","category":"business","job":"operations","example_prompt":"Highlight the differences between these two versions of FinCEN\'s Investment Adviser AML regulations:\\n\\nProposed version (2015): https://www.federalregister.gov/documents/2015/09/01/2015-21318/anti-money-laundering-program-and-suspicious-activity-report-filing-requirements-for-registered\\n\\nFinal version (2024): https://www.federalregister.gov/documents/2024/09/04/2024-19260/financial-crimes-enforcement-network-anti-money-launderingcountering-the-financing-of-terrorism\\n\\nFocus on key changes in requirements for investment advisers\' AML/CFT programs and how they affect compliance obligations.","example_result":"# Regulatory Change Analysis Report\\n\\nDocument: FinCEN Investment Adviser AML Regulations\\nComparison Period: 2015 (Proposed) vs 2024 (Final)\\n\\n## 1. Core Program Requirements\\n\\n### Risk Assessment\\n```diff\\n2015 Version:\\n- General risk assessment requirement\\n- Focus on client-based risks\\n\\n2024 Version:\\n+ Comprehensive risk assessment framework\\n+ Enterprise-wide risk consideration\\n+ Required annual updates\\n+ Documentation of methodology\\n```\\n\\n### Internal Controls\\n```diff\\n2015 Version:\\n- Basic policies and procedures\\n- General oversight requirements\\n\\n2024 Version:\\n+ Detailed control framework\\n+ Technology-based monitoring systems\\n+ Transaction monitoring requirements\\n+ Automated alert generation\\n+ Risk-based investigation procedures\\n```\\n\\n## 2. Customer Due Diligence\\n\\n### Initial Verification\\n```diff\\n2015 Version:\\n- Basic identity verification\\n- Document collection\\n\\n2024 Version:\\n+ Enhanced verification procedures\\n+ Beneficial ownership requirements\\n+ Source of funds documentation\\n+ Risk-based enhanced due diligence\\n+ Ongoing monitoring requirements\\n```\\n\\n### Periodic Review\\n```diff\\n2015 Version:\\n- Annual review recommendation\\n\\n2024 Version:\\n+ Risk-based review schedule\\n+ Trigger events for review\\n+ Documentation requirements\\n+ Update procedures\\n```\\n\\n## 3. Suspicious Activity Reporting\\n\\n### Filing Requirements\\n```diff\\n2015 Version:\\n- 30-day filing deadline\\n- Basic suspicious activity indicators\\n\\n2024 Version:\\n+ 30-day filing deadline (unchanged)\\n+ Expanded suspicious activity indicators\\n+ Automated detection requirements\\n+ Investigation documentation standards\\n+ Quality assurance procedures\\n```\\n\\n### Technology Requirements\\n```diff\\n2015 Version:\\n- Manual monitoring permitted\\n\\n2024 Version:\\n+ Automated monitoring required for firms >$1B AUM\\n+ System validation requirements\\n+ Alert optimization standards\\n+ Data quality controls\\n```\\n\\n## 4. Training Requirements\\n\\n### Staff Training\\n```diff\\n2015 Version:\\n- Annual training requirement\\n- Basic AML topics\\n\\n2024 Version:\\n+ Role-specific training programs\\n+ Certification requirements\\n+ Testing components\\n+ Documentation standards\\n+ Frequency based on risk rating\\n```\\n\\n## 5. Implementation Timeline\\n\\n```\\n2024 Final Rule:\\n\\n[Month 0] Rule Publication\\n\u251c\u2500 [Month 6] Risk Assessment Framework\\n\u251c\u2500 [Month 9] Policy Development\\n\u251c\u2500 [Month 12] Technology Implementation\\n\u251c\u2500 [Month 15] Staff Training\\n\u2514\u2500 [Month 18] Full Compliance Required\\n```\\n\\n## 6. Key Impact Areas\\n\\n1. Technology Infrastructure:\\n```\\nRequired Updates:\\n- Transaction monitoring systems\\n- Customer risk rating tools\\n- Case management software\\n- Regulatory reporting platform\\n```\\n\\n2. Staffing Requirements:\\n```\\nNew Positions Needed:\\n- AML Compliance Officer\\n- Transaction Monitoring Analysts\\n- Investigation Specialists\\n- Technology Support Staff\\n```\\n\\n3. Budget Implications:\\n```\\nEstimated Costs:\\n- Technology: $500K - $2M\\n- Staffing: $300K - $1M annually\\n- Training: $50K - $200K annually\\n- Documentation: $100K - $300K\\n```\\n\\n## 7. Action Items\\n\\n### Immediate (0-3 months):\\n```\\n1. Gap Analysis\\n   - Review current program\\n   - Identify deficiencies\\n   - Develop remediation plan\\n\\n2. Technology Assessment\\n   - Evaluate current systems\\n   - Identify needed upgrades\\n   - Request vendor proposals\\n```\\n\\n### Short-term (3-6 months):\\n```\\n3. Policy Updates\\n   - Revise procedures\\n   - Update manuals\\n   - Create new forms\\n\\n4. Training Development\\n   - Design new programs\\n   - Create materials\\n   - Schedule sessions\\n```\\n\\n### Long-term (6-18 months):\\n```\\n5. System Implementation\\n   - Install new software\\n   - Migrate data\\n   - Test controls\\n\\n6. Program Integration\\n   - Roll out changes\\n   - Monitor effectiveness\\n   - Adjust as needed\\n```\\n\\nWould you like me to:\\n1. Generate detailed implementation timeline?\\n2. Create budget breakdown?\\n3. Draft policy templates?\\n4. Develop training materials?","extensions":[{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[{"name":"document_name","description":"The name/title of the regulatory document being compared","required":true},{"name":"prior_version_url","description":"URL to the previous version of the document","required":true},{"name":"final_version_url","description":"URL to the final/current version of the document","required":true}]}]}')},86867:e=>{"use strict";e.exports=JSON.parse('{"id":"business-retail-market-monitor","title":"Monitor Top Retailers Market Activity","description":"Generate and maintain an automated dashboard tracking top retailers\' digital presence and market activities","category":"business","job":"marketing-content","example_prompt":"1. Search the web for the top 5 most popular retailers.\\n2. For each identified retailer, generate a comprehensive report on each retailer\'s:\\n* Website updates\\n* New product launches\\n* Social media engagement\\n* Recent customer reviews\\n* Press mentions\\n3. Generate an HTML dashboard based on findings for each retailer\\n4. Open the dashboard in a browser\\n5. Automation Script to pull new results every 30 days","example_result":"I\'ve created a retail market monitoring dashboard. Here\'s the analysis and implementation:\\n\\n1. Top Retailers Identified:\\n```json\\n{\\n  \\"retailers\\": [\\n    {\\n      \\"name\\": \\"Amazon\\",\\n      \\"market_cap\\": \\"$1.78T\\",\\n      \\"monthly_visitors\\": \\"2.7B\\"\\n    },\\n    {\\n      \\"name\\": \\"Walmart\\",\\n      \\"market_cap\\": \\"$420B\\",\\n      \\"monthly_visitors\\": \\"410M\\"\\n    },\\n    {\\n      \\"name\\": \\"Target\\",\\n      \\"market_cap\\": \\"$65B\\",\\n      \\"monthly_visitors\\": \\"250M\\"\\n    },\\n    {\\n      \\"name\\": \\"Costco\\",\\n      \\"market_cap\\": \\"$245B\\",\\n      \\"monthly_visitors\\": \\"120M\\"\\n    },\\n    {\\n      \\"name\\": \\"Home Depot\\",\\n      \\"market_cap\\": \\"$350B\\",\\n      \\"monthly_visitors\\": \\"170M\\"\\n    }\\n  ]\\n}\\n```\\n\\n2. Monitoring Script:\\n```python\\nimport requests\\nfrom bs4 import BeautifulSoup\\nimport pandas as pd\\nfrom datetime import datetime\\nimport schedule\\nimport time\\n\\nclass RetailMonitor:\\n    def __init__(self, retailers):\\n        self.retailers = retailers\\n        self.data = {}\\n\\n    def fetch_website_updates(self, retailer):\\n        # Monitor website changes\\n        url = f\\"https://www.{retailer.lower()}.com\\"\\n        response = requests.get(url)\\n        return {\\n            \'last_modified\': response.headers.get(\'last-modified\'),\\n            \'content_hash\': hash(response.text)\\n        }\\n\\n    def get_social_metrics(self, retailer):\\n        # Fetch social media engagement\\n        platforms = [\'twitter\', \'facebook\', \'instagram\']\\n        metrics = {}\\n        for platform in platforms:\\n            # API calls to fetch metrics\\n            metrics[platform] = self.fetch_social_metrics(retailer, platform)\\n        return metrics\\n\\n    def analyze_reviews(self, retailer):\\n        # Aggregate customer reviews\\n        sources = [\'trustpilot\', \'google\', \'sitejabber\']\\n        reviews = []\\n        for source in sources:\\n            reviews.extend(self.fetch_reviews(retailer, source))\\n        return self.analyze_sentiment(reviews)\\n\\n    def generate_report(self):\\n        for retailer in self.retailers:\\n            self.data[retailer] = {\\n                \'website\': self.fetch_website_updates(retailer),\\n                \'social\': self.get_social_metrics(retailer),\\n                \'reviews\': self.analyze_reviews(retailer),\\n                \'press\': self.fetch_press_mentions(retailer),\\n                \'timestamp\': datetime.now()\\n            }\\n        return self.data\\n\\n    def update_dashboard(self):\\n        self.generate_report()\\n        self.create_html_dashboard()\\n```\\n\\n3. Dashboard HTML Template:\\n```html\\n<!DOCTYPE html>\\n<html lang=\\"en\\">\\n<head>\\n    <meta charset=\\"UTF-8\\">\\n    <title>Retail Market Monitor</title>\\n    <link href=\\"https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css\\" rel=\\"stylesheet\\">\\n    <script src=\\"https://cdn.jsdelivr.net/npm/chart.js\\"><\/script>\\n</head>\\n<body class=\\"bg-gray-100\\">\\n    <div class=\\"container mx-auto px-4 py-8\\">\\n        <h1 class=\\"text-3xl font-bold mb-8\\">Retail Market Monitor</h1>\\n        \\n        \x3c!-- Retailer Cards --\x3e\\n        <div class=\\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6\\">\\n            {% for retailer in retailers %}\\n            <div class=\\"bg-white rounded-lg shadow-lg p-6\\">\\n                <h2 class=\\"text-xl font-semibold mb-4\\">{{ retailer.name }}</h2>\\n                \\n                \x3c!-- Website Updates --\x3e\\n                <div class=\\"mb-4\\">\\n                    <h3 class=\\"font-medium\\">Website Updates</h3>\\n                    <p>Last Modified: {{ retailer.website.last_modified }}</p>\\n                </div>\\n                \\n                \x3c!-- Social Metrics --\x3e\\n                <div class=\\"mb-4\\">\\n                    <h3 class=\\"font-medium\\">Social Engagement</h3>\\n                    <canvas id=\\"social-chart-{{ retailer.id }}\\"></canvas>\\n                </div>\\n                \\n                \x3c!-- Reviews Summary --\x3e\\n                <div class=\\"mb-4\\">\\n                    <h3 class=\\"font-medium\\">Customer Sentiment</h3>\\n                    <div class=\\"flex items-center\\">\\n                        <div class=\\"w-full bg-gray-200 rounded-full h-2.5\\">\\n                            <div class=\\"bg-blue-600 h-2.5 rounded-full\\" style=\\"width: {{ retailer.sentiment }}%\\"></div>\\n                        </div>\\n                        <span class=\\"ml-2\\">{{ retailer.sentiment }}%</span>\\n                    </div>\\n                </div>\\n                \\n                \x3c!-- Press Mentions --\x3e\\n                <div>\\n                    <h3 class=\\"font-medium\\">Recent Press</h3>\\n                    <ul class=\\"list-disc pl-5\\">\\n                        {% for article in retailer.press[:3] %}\\n                        <li>{{ article.title }}</li>\\n                        {% endfor %}\\n                    </ul>\\n                </div>\\n            </div>\\n            {% endfor %}\\n        </div>\\n        \\n        \x3c!-- Trends Graph --\x3e\\n        <div class=\\"mt-8 bg-white rounded-lg shadow-lg p-6\\">\\n            <h2 class=\\"text-xl font-semibold mb-4\\">Market Trends</h2>\\n            <canvas id=\\"trends-chart\\"></canvas>\\n        </div>\\n    </div>\\n</body>\\n</html>\\n```\\n\\n4. Automation Setup:\\n```python\\n# Schedule updates\\ndef job():\\n    monitor = RetailMonitor(retailers)\\n    monitor.update_dashboard()\\n\\nschedule.every(30).days.do(job)\\n\\nwhile True:\\n    schedule.run_pending()\\n    time.sleep(3600)  # Check every hour\\n```\\n\\n5. Sample Dashboard Data:\\n```json\\n{\\n  \\"Amazon\\": {\\n    \\"website_updates\\": {\\n      \\"new_features\\": [\\"Buy with Prime integration\\", \\"Live shopping\\"],\\n      \\"product_launches\\": 127,\\n      \\"last_updated\\": \\"2025-03-30T15:45:00Z\\"\\n    },\\n    \\"social_metrics\\": {\\n      \\"twitter\\": {\\n        \\"followers\\": 5200000,\\n        \\"engagement_rate\\": 2.8,\\n        \\"monthly_mentions\\": 45000\\n      },\\n      \\"facebook\\": {\\n        \\"followers\\": 12000000,\\n        \\"engagement_rate\\": 1.9,\\n        \\"monthly_reach\\": 8500000\\n      }\\n    },\\n    \\"customer_sentiment\\": {\\n      \\"overall_score\\": 4.2,\\n      \\"total_reviews\\": 25000,\\n      \\"positive_percentage\\": 84\\n    },\\n    \\"press_mentions\\": [\\n      {\\n        \\"title\\": \\"Amazon Expands Same-Day Delivery\\",\\n        \\"source\\": \\"Reuters\\",\\n        \\"date\\": \\"2025-03-29\\"\\n      }\\n    ]\\n  }\\n}\\n```\\n\\nWould you like me to:\\n1. Add more retailers to monitor?\\n2. Include additional metrics?\\n3. Customize the dashboard layout?\\n4. Set up email notifications?","extensions":[{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[{"name":"dashboard_path","description":"Path where the dashboard HTML should be saved","required":false}]},{"name":"Tavily Web Search","command":"npx -y tavily-mcp","is_builtin":false,"link":"https://github.com/tavily-ai/tavily-mcp","environmentVariables":[{"name":"num_retailers","description":"Number of top retailers to monitor","required":false},{"name":"update_frequency","description":"How often to update the dashboard in days","required":false},{"name":"search_type","description":"Tavily Web Search type (comprehensive or news)","required":false}]}]}')},19948:e=>{"use strict";e.exports=JSON.parse('{"id":"dev-roll-plan-analyzer","title":"Analyze Production Change ROLL Plans","description":"Analyze and validate infrastructure change ROLL plans for production environments","category":"technical","job":"project-management","example_prompt":"You are an expert in cloud infrastructure, security, and reliability engineering. Your goal is to analyze manual production changes documented in a ROLL plan, which governs high-risk changes to infrastructure and services that impact system state and production environments.\\nA ROLL plan can contain any formatted change that any team is making that impacts production.\\nI will provide a reference ROLL plan named\\nROLL - SAMPLE.xml, which is a past real-world ROLL plan exported from JIRA. This is for context so you can understand\\nthe structure and details of a typical ROLL plan.\\nHowever, the actual ROLL plan you need to analyze will be uploaded separately.","example_result":"I\'ve analyzed the ROLL plan for the database migration change. Here\'s my comprehensive review:\\n\\n# ROLL Plan Analysis\\n\\n## 1. Change Overview\\n\\n```yaml\\nChange Type: Database Migration\\nEnvironment: Production\\nImpact Level: High\\nDuration: 4 hours\\nTeams Involved:\\n  - Database Operations\\n  - Application Development\\n  - Site Reliability\\n  - Security\\n```\\n\\n## 2. Risk Assessment\\n\\n### Critical Risks Identified:\\n```\\n1. Data Integrity\\n   - Risk: Potential data loss during migration\\n   - Mitigation: Point-in-time backup before change\\n   - Verification: Checksum validation\\n\\n2. Service Availability\\n   - Risk: Extended downtime during cutover\\n   - Mitigation: Rolling update strategy\\n   - Verification: Health check monitoring\\n\\n3. Performance Impact\\n   - Risk: Degraded performance post-migration\\n   - Mitigation: Performance baseline comparison\\n   - Verification: Load testing pre-production\\n```\\n\\n## 3. Prerequisites Check\\n\\n```diff\\n+ Database backup completed and verified\\n+ Rollback scripts tested in staging\\n+ Performance baseline established\\n+ Monitoring alerts configured\\n- Load testing in pre-production pending\\n- Security scan of new configuration needed\\n```\\n\\n## 4. Step-by-Step Analysis\\n\\n### Pre-Change Steps:\\n```sql\\n-- Step 1: Backup Verification\\nSELECT COUNT(*), SUM(CHECKSUM(*)) \\nFROM critical_tables;\\n\\n-- Step 2: Connection Count\\nSELECT COUNT(*) \\nFROM pg_stat_activity \\nWHERE state = \'active\';\\n\\n-- Step 3: Replication Status\\nSELECT * \\nFROM pg_stat_replication;\\n```\\n\\n### Main Migration Steps:\\n```bash\\n# Step 4: Schema Migration\\n./migrate.sh --env=prod --version=v2.5.0\\n\\n# Step 5: Data Transfer\\npsql -f transfer_data.sql\\n\\n# Step 6: Index Rebuild\\n./rebuild_indexes.sh --parallel 4\\n```\\n\\n### Validation Steps:\\n```python\\ndef validate_migration():\\n    checks = [\\n        check_row_counts(),\\n        verify_constraints(),\\n        test_replication(),\\n        validate_performance()\\n    ]\\n    return all(checks)\\n```\\n\\n## 5. Rollback Procedure\\n\\n```yaml\\nTrigger Conditions:\\n  - Data validation failure\\n  - Performance degradation >20%\\n  - Replication lag >10 minutes\\n\\nRollback Steps:\\n  1. Stop application traffic\\n  2. Restore from backup\\n  3. Verify data integrity\\n  4. Resume application traffic\\n\\nTime to Complete: 45 minutes\\n```\\n\\n## 6. Monitoring Plan\\n\\n```json\\n{\\n  \\"metrics\\": {\\n    \\"database\\": [\\n      \\"queries_per_second\\",\\n      \\"average_response_time\\",\\n      \\"active_connections\\",\\n      \\"buffer_cache_hit_ratio\\"\\n    ],\\n    \\"application\\": [\\n      \\"error_rate\\",\\n      \\"latency_p95\\",\\n      \\"success_rate\\",\\n      \\"throughput\\"\\n    ],\\n    \\"system\\": [\\n      \\"cpu_usage\\",\\n      \\"memory_usage\\",\\n      \\"disk_io\\",\\n      \\"network_throughput\\"\\n    ]\\n  },\\n  \\"alerts\\": {\\n    \\"critical\\": {\\n      \\"error_rate\\": \\">5%\\",\\n      \\"latency\\": \\">500ms\\",\\n      \\"replication_lag\\": \\">60s\\"\\n    },\\n    \\"warning\\": {\\n      \\"error_rate\\": \\">2%\\",\\n      \\"latency\\": \\">200ms\\",\\n      \\"replication_lag\\": \\">30s\\"\\n    }\\n  }\\n}\\n```\\n\\n## 7. Communication Plan\\n\\n```yaml\\nPre-Change:\\n  - Announcement: T-7 days\\n  - Reminder: T-1 day\\n  - Final notice: T-1 hour\\n\\nDuring Change:\\n  - Status updates: Every 30 minutes\\n  - Incident channel: #db-migration\\n  - Emergency contacts listed\\n\\nPost-Change:\\n  - Completion notice\\n  - Performance report\\n  - Incident review if needed\\n```\\n\\n## 8. Recommendations\\n\\n1. Critical Items:\\n```\\n\u2757 Add performance acceptance criteria\\n\u2757 Include specific rollback triggers\\n\u2757 Detail data validation queries\\n```\\n\\n2. Improvements:\\n```\\n- Add canary deployment step\\n- Include query performance baselines\\n- Expand monitoring metrics\\n```\\n\\n3. Missing Elements:\\n```\\n- Backup retention policy\\n- Compliance verification\\n- Audit log requirements\\n```\\n\\nWould you like me to:\\n1. Generate detailed validation queries?\\n2. Create monitoring dashboard?\\n3. Expand rollback procedures?\\n4. Add security controls?","extensions":[{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[]},{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[]}]}')},64926:e=>{"use strict";e.exports=JSON.parse('{"id":"sales-performance-analysis","title":"Monthly Sales Performance Analysis","description":"Analyze monthly sales data to identify top performing stores and significant trends","category":"business","job":"data-analytics","example_prompt":"Please review these two documents named {month1} Orders and {month2} Orders. Can you create insights on top performing stores and any significant movements.","example_result":"I\'ve analyzed the sales data for February and March 2025. Here\'s my comprehensive analysis:\\n\\n# Monthly Sales Performance Report\\n\\n## 1. Executive Summary\\n\\n```yaml\\nTotal Revenue:\\n  February: $4.2M\\n  March: $4.8M\\n  Growth: +14.3%\\n\\nTotal Orders:\\n  February: 28,450\\n  March: 31,275\\n  Growth: +9.9%\\n\\nAverage Order Value:\\n  February: $147.63\\n  March: $153.48\\n  Growth: +4.0%\\n```\\n\\n## 2. Top Performing Stores\\n\\n```sql\\n-- Top 5 Stores by Revenue\\nSELECT \\n    store_id,\\n    location,\\n    SUM(revenue) as total_revenue,\\n    COUNT(order_id) as order_count,\\n    AVG(basket_size) as avg_basket\\nFROM march_orders\\nGROUP BY store_id, location\\nORDER BY total_revenue DESC\\nLIMIT 5;\\n```\\n\\n### Results:\\n```\\n1. Store #127 (San Francisco)\\n   Revenue: $425,000 (+15% MoM)\\n   Orders: 2,450 (+12% MoM)\\n   Avg Basket: $173.47 (+3% MoM)\\n\\n2. Store #089 (Seattle)\\n   Revenue: $398,000 (+18% MoM)\\n   Orders: 2,380 (+14% MoM)\\n   Avg Basket: $167.23 (+4% MoM)\\n\\n3. Store #156 (Austin)\\n   Revenue: $375,000 (+22% MoM)\\n   Orders: 2,275 (+16% MoM)\\n   Avg Basket: $164.84 (+5% MoM)\\n```\\n\\n## 3. Key Trends\\n\\n### Product Categories\\n```python\\nimport pandas as pd\\n\\n# Category performance analysis\\ndf = pd.DataFrame(march_data)\\ncat_growth = df.groupby(\'category\')[\'revenue\'].sum().pct_change()\\n\\nprint(\\"Category Growth Rates:\\")\\nprint(cat_growth.sort_values(ascending=False))\\n```\\n\\n```\\nFastest Growing Categories:\\n1. Electronics: +24.5%\\n   - Driven by new product launches\\n   - Higher ASP in premium segment\\n\\n2. Home & Garden: +18.7%\\n   - Seasonal transition impact\\n   - Strong performance in outdoor\\n\\n3. Apparel: +15.2%\\n   - Spring collection launch\\n   - Improved inventory availability\\n```\\n\\n## 4. Customer Insights\\n\\n```json\\n{\\n  \\"customer_segments\\": {\\n    \\"new_customers\\": {\\n      \\"count\\": 8450,\\n      \\"growth\\": \\"+12%\\",\\n      \\"avg_first_purchase\\": 89.50\\n    },\\n    \\"returning\\": {\\n      \\"count\\": 22825,\\n      \\"growth\\": \\"+8%\\",\\n      \\"avg_purchase\\": 167.25\\n    },\\n    \\"loyalty_members\\": {\\n      \\"count\\": 15380,\\n      \\"growth\\": \\"+15%\\",\\n      \\"avg_basket\\": 195.75\\n    }\\n  }\\n}\\n```\\n\\n## 5. Regional Performance\\n\\n```sql\\n-- Regional analysis\\nSELECT \\n    region,\\n    COUNT(DISTINCT store_id) as store_count,\\n    SUM(revenue) as total_revenue,\\n    SUM(revenue) / COUNT(DISTINCT store_id) as revenue_per_store\\nFROM march_orders\\nGROUP BY region\\nORDER BY total_revenue DESC;\\n```\\n\\n### Results Map:\\n```\\nWest Coast: $1.8M (+16%)\\n\u251c\u2500 CA: $980K\\n\u251c\u2500 WA: $520K\\n\u2514\u2500 OR: $300K\\n\\nSouthwest: $1.2M (+19%)\\n\u251c\u2500 TX: $780K\\n\u251c\u2500 AZ: $280K\\n\u2514\u2500 NV: $140K\\n\\nNortheast: $1.0M (+12%)\\n\u251c\u2500 NY: $580K\\n\u251c\u2500 MA: $280K\\n\u2514\u2500 CT: $140K\\n```\\n\\n## 6. Operational Metrics\\n\\n```yaml\\nInventory Turnover:\\n  February: 4.2\\n  March: 4.5\\n  Change: +7.1%\\n\\nOut-of-Stock Rate:\\n  February: 3.8%\\n  March: 3.2%\\n  Change: -15.8%\\n\\nReturn Rate:\\n  February: 5.5%\\n  March: 5.2%\\n  Change: -5.5%\\n```\\n\\n## 7. Recommendations\\n\\n1. Inventory Optimization:\\n```\\n- Increase stock levels for top performers\\n- Adjust regional allocation based on growth\\n- Implement predictive reordering\\n```\\n\\n2. Marketing Focus:\\n```\\n- Promote high-growth categories\\n- Target loyalty program enrollment\\n- Increase regional marketing in growth areas\\n```\\n\\n3. Store Operations:\\n```\\n- Share best practices from top stores\\n- Optimize staffing for peak periods\\n- Enhance training in underperforming regions\\n```\\n\\nWould you like me to:\\n1. Generate detailed store-level reports?\\n2. Create visualization dashboard?\\n3. Develop forecast models?\\n4. Analyze specific product categories?","extensions":[{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[]},{"name":"Google Drive","command":"npx -y @modelcontextprotocol/server-gdrive","is_builtin":false,"environmentVariables":[{"name":"GDRIVE_OAUTH_PATH","description":"/Users/<username>/.config/gcp-oauth.keys.json / ","required":true},{"name":"GDRIVE_CREDENTIALS_PATH","description":"/Users/<username>/.config/.gdrive-server-credentials.json /","required":true}]}]}')},58156:e=>{"use strict";e.exports=JSON.parse('{"id":"developer-security-patterns","title":"Learn Security Vulnerability Patterns","description":"Store and analyze security vulnerability patterns and their relationships","category":"technical","job":"engineering","example_prompt":"Goose, learn these security vulnerability patterns and their relationships:\\n\\n1. SQL Injection relates to:\\n    - Unvalidated database inputs\\n    - Data theft risks\\n    - Parameterized query solutions\\n    \\n2. XSS Vulnerabilities connect to:\\n    - Unescaped user output\\n    - Session hijacking risks\\n    - Content sanitization fixes\\n\\n3.Authentication Weaknesses link to:\\n    - Session management\\n    - Account compromise\\n    - JWT-based solutions","example_result":"I\'ve analyzed the security vulnerability patterns and stored their relationships. Here\'s what I\'ve learned:\\n\\nSQL Injection Patterns:\\n- Primary Risk: Unauthorized database access through unvalidated inputs\\n- Impact: Data theft, data manipulation, system compromise\\n- Key Mitigation: Implement parameterized queries, input validation\\n- Related Concepts: Input sanitization, prepared statements\\n\\nXSS Vulnerability Patterns:\\n- Primary Risk: Client-side code injection via unescaped output\\n- Impact: Session hijacking, data theft, malicious actions\\n- Key Mitigation: Content sanitization, output encoding\\n- Related Concepts: CSP headers, input validation\\n\\nAuthentication Weakness Patterns:\\n- Primary Risk: Unauthorized access through session/token exploitation\\n- Impact: Account compromise, privilege escalation\\n- Key Mitigation: JWT-based authentication, secure session management\\n- Related Concepts: Token validation, session timeout\\n\\nI\'ve noted the interconnections between these vulnerabilities. Would you like me to analyze any specific relationship in more detail?","extensions":[{"name":"Knowledge Graph","command":"npx -y @modelcontextprotocol/server-memory","is_builtin":false,"environmentVariables":[]},{"name":"Developer","command":"developer","is_builtin":true,"environmentVariables":[]}]}')},5308:e=>{"use strict";e.exports=JSON.parse('{"id":"social-post-adaptation","title":"Adapt Social Post for Platform","description":"Convert a social media post to fit different platform requirements and best practices","category":"productivity","job":"marketing-content","example_prompt":"Please adapt this post for [Target Platform]. Consider:\\n\\n1. Character limits\\n2. Platform-specific features\\n3. Format conventions\\n4. Hashtag usage\\n5. Link formatting\\n6. Media recommendations\\n7. Best posting practices\\n\\nOriginal Post ([Original Platform]):\\n[Post Content]\\n\\nProvide the adapted post with any relevant platform-specific recommendations.","example_result":"I\'ve analyzed your LinkedIn post and adapted it for Twitter. Here\'s the optimized version:\\n\\nOriginal LinkedIn Post:\\nExcited to announce our new AI-powered analytics dashboard! After months of development, we\'ve created a solution that helps businesses understand their data through natural language queries. No more complex SQL or confusing charts - just ask questions and get instant insights. Check out the full feature list and demo at example.com/analytics-launch\\n\\nAdapted for Twitter:\\nIntroducing our new AI analytics dashboard \ud83d\udcca\\n\\nAsk questions, get instant insights - no SQL needed!\\n\\nKey features:\\n\u2022 Natural language queries\\n\u2022 Instant visualizations\\n\u2022 Custom reporting\\n\\nSee it in action \u2b07\ufe0f\\nexample.com/demo\\n\\n#AIAnalytics #BusinessIntelligence #DataScience\\n\\nPlatform-specific recommendations:\\n1. Kept under 280 characters\\n2. Used bullet points for scanability\\n3. Added relevant hashtags\\n4. Included eye-catching emoji\\n5. Changed link to shorter demo page\\n6. Added visual cue arrow for CTA\\n\\nWould you like me to adapt this for any other platforms?","extensions":[{"name":"Google Drive","command":"npx -y @modelcontextprotocol/server-gdrive","is_builtin":false,"link":"https://block.github.io/goose/v1/extensions/google-drive","environmentVariables":[{"name":"GDRIVE_OAUTH_PATH","description":"/Users/<username>/.config/gcp-oauth.keys.json","required":true},{"name":"GDRIVE_CREDENTIALS_PATH","description":"/Users/<username>/.config/.gdrive-server-credentials.json","required":true}]},{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[]}]}')},88623:e=>{"use strict";e.exports=JSON.parse('{"id":"misc-system-control-research","title":"Control Computer Settings","description":"Automate system settings while conducting parallel research tasks","category":"productivity","job":"operations","example_prompt":"Goose, I need to decompress while researching AI models for tomorrow\'s meeting. Can you create a relaxing environment and help me research?\\n\\n1. Play classical music in [your preferred app]\\n2. Dim screen brightness (2 levels)\\n3. Research current flagship AI models:\\n    * Verify availability\\n    * Collect: release date, features, pricing, context window\\n    * Use official sources only\\n4. Create \\"ai-models-comparison.csv\\" on desktop with collected data\\n5. Launch Numbers and open the CSV file\\n6. Reset brightness and close Safari","example_result":"I\'ll help you create a relaxing environment and conduct the research. Let me handle this step by step:\\n\\n1. Setting up your environment:\\n- Opened Music app and started playing Bach\'s Air on G String\\n- Reduced screen brightness by 2 levels\\n\\n2. Research findings on flagship AI models:\\n\\nGPT-4 Turbo:\\n- Release: March 2024\\n- Context: 128K tokens\\n- Features: Multimodal, code interpreter\\n- Pricing: $0.01/1K input tokens\\n\\nClaude 3 Opus:\\n- Release: February 2024\\n- Context: 200K tokens\\n- Features: Advanced reasoning, code generation\\n- Pricing: $15/million tokens\\n\\n3. Created and populated ai-models-comparison.csv on your desktop\\n\\n4. Opened Numbers with the comparison file\\n\\n5. Environment restoration:\\n- Reset screen brightness to original level\\n- Closed Safari browser windows\\n\\nThe comparison file is now open in Numbers. Would you like me to adjust any of the collected information or environment settings?","extensions":[{"name":"Computer Controller","command":"computercontroller","is_builtin":true,"environmentVariables":[]}]}')},36658:e=>{"use strict";e.exports=JSON.parse('{"id":"youtube-to-blog","title":"Convert YouTube Video to Blog Post","description":"Generate a blog post from a YouTube video transcript","category":"productivity","job":"marketing-content","featured":true,"example_prompt":"Get the transcript from this youtube video [link to video]. Then, summarize it into a blog post.","example_result":"I\'ve retrieved the transcript from the YouTube video about machine learning deployment best practices and created a blog post summary:\\n\\nTitle: Machine Learning in Production: Essential Best Practices for Deployment\\n\\nDeploying machine learning models to production environments requires careful planning and execution. In this comprehensive guide, we\'ll explore key best practices that ensure successful ML deployments.\\n\\nModel Versioning and Documentation\\n- Implement semantic versioning for models (major.minor.patch)\\n- Document all model assumptions and limitations\\n- Track training data versions and preprocessing steps\\n\\nMonitoring and Observability\\n- Set up comprehensive model performance metrics\\n- Monitor prediction latency and resource usage\\n- Implement data drift detection\\n- Create alerting systems for critical metrics\\n\\nScalability Considerations\\n- Design for horizontal scaling\\n- Implement efficient batch prediction capabilities\\n- Consider hardware requirements and costs\\n- Use container orchestration for deployment\\n\\nTesting and Validation\\n- Create comprehensive test suites for model behavior\\n- Validate inputs and outputs thoroughly\\n- Perform A/B testing before full deployment\\n- Test system behavior under load\\n\\nConclusion:\\nSuccessful ML deployment requires a systematic approach to versioning, monitoring, scaling, and testing. By following these best practices, teams can ensure their models perform reliably in production environments.\\n\\nWould you like me to expand on any specific aspect of the blog post?","extensions":[{"name":"YouTube Transcript","command":"uvx --from git+https://github.com/jkawamoto/mcp-youtube-transcript mcp-youtube-transcript","is_builtin":false,"environmentVariables":[]}]}')}}]);